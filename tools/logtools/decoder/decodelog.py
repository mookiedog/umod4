#!/usr/bin/env python3

# Decode logs generated by the umod4 system.
#
# To do this 'manually' to decode a log file, invoke this script as follows:
#
#    <path-to-decodelog.py> <binary-log-file-to-decode>
#
# example:
#    ~/projects/umod4/tools/src/decodelog.py ~/logs/log.17
#

import sys
import os
import math
import argparse
from abc import ABC, abstractmethod
from datetime import datetime, timezone

# HDF5 support - only imported if needed
try:
    import numpy as np
    import h5py
    HDF5_AVAILABLE = True
except ImportError:
    HDF5_AVAILABLE = False
    np = None
    h5py = None

# Logsyms - Try to import at module level for Nuitka bundling
# If not available (during development before CMake build), will be imported later from venv
try:
    import Logsyms
    LOGSYMS_PRELOADED = True
except ImportError:
    Logsyms = None
    LOGSYMS_PRELOADED = False

# ================================================================================================
# Output Handler Classes
# ================================================================================================

class OutputHandler(ABC):
    """Abstract base class for handling decoded log output in different formats."""

    def __init__(self, L):
        """Initialize with Logsyms reference.

        Args:
            L: Logsyms class reference containing all LOGID constants
        """
        self.L = L
        self.time_ns = 0  # Unified nanosecond counter from log start
        self.prev_timestamp = -1  # Previous raw timestamp for delta calculation
        self.record_count = 0

        # State variables for accumulating values
        self.cr_ts = -1
        self.cr_ts_prev = -1
        self.elapsed = -1
        self.crid = -1
        self.cridPrev = -1
        self.fc_off = 0
        self.rc_off = 0
        self.map = -1
        self.aap = -1
        self.vm_V = -1
        self.vta = -1
        self.fi_on = -1
        self.ri_on = -1
        self.fi_dur = 0
        self.ri_dur = 0
        self.secs = -1
        self.tha_C = -1
        self.thw_C = -1
        self.rpm_avg = 0.0

        # EPROM load tracking
        self.epromIdString = ""
        self.currentEpromId = ""

        # GPS time tracking for back-calculation
        self.gps_sync_time_ns = None  # When GPS first synced
        self.gps_first_timestamp = None  # The GPS time when sync occurred

    def update_time(self, has_timestamp=False, raw_timestamp=None):
        """Update the unified nanosecond counter.

        Args:
            has_timestamp: True if this event has a raw timestamp
            raw_timestamp: The raw 16-bit timestamp value (if has_timestamp=True)
        """
        if has_timestamp and raw_timestamp is not None:
            if self.prev_timestamp >= 0:
                # Calculate delta, handling wraparound
                delta_ticks = raw_timestamp - self.prev_timestamp
                if delta_ticks < 0:
                    delta_ticks += 65536  # Handle 16-bit wraparound
                # Each tick is 2 microseconds = 2000 nanoseconds
                self.time_ns += delta_ticks * 2000
            self.prev_timestamp = raw_timestamp
        else:
            # Untimestamped event - increment by 1ns to preserve sequence
            self.time_ns += 1

    @abstractmethod
    def begin(self):
        """Called once before processing begins."""
        pass

    @abstractmethod
    def end(self):
        """Called once after all processing is complete."""
        pass

    @abstractmethod
    def write_ecu_log_version(self, version):
        pass

    @abstractmethod
    def write_ep_log_version(self, version):
        pass

    @abstractmethod
    def write_wp_log_version(self, version):
        pass

    @abstractmethod
    def write_cpu_event(self, event_type):
        pass

    @abstractmethod
    def write_l4000_event(self, value):
        pass

    @abstractmethod
    def write_front_inj_on(self, timestamp):
        pass

    @abstractmethod
    def write_front_inj_dur(self, duration):
        pass

    @abstractmethod
    def write_rear_inj_on(self, timestamp):
        pass

    @abstractmethod
    def write_rear_inj_dur(self, duration):
        pass

    @abstractmethod
    def write_front_coil_on(self, timestamp):
        pass

    @abstractmethod
    def write_front_coil_off(self, timestamp):
        pass

    @abstractmethod
    def write_rear_coil_on(self, timestamp):
        pass

    @abstractmethod
    def write_rear_coil_off(self, timestamp):
        pass

    @abstractmethod
    def write_front_coil_manual_on(self, timestamp):
        pass

    @abstractmethod
    def write_front_coil_manual_off(self, timestamp):
        pass

    @abstractmethod
    def write_rear_coil_manual_on(self, timestamp):
        pass

    @abstractmethod
    def write_rear_coil_manual_off(self, timestamp):
        pass

    @abstractmethod
    def write_front_ign_delay(self, degrees):
        pass

    @abstractmethod
    def write_rear_ign_delay(self, degrees):
        pass

    @abstractmethod
    def write_5ms_marker(self):
        pass

    @abstractmethod
    def write_p6_max_marker(self):
        pass

    @abstractmethod
    def write_fuel_pump(self, state):
        pass

    @abstractmethod
    def write_error_L000C(self, bitmap):
        pass

    @abstractmethod
    def write_error_L000D(self, bitmap):
        pass

    @abstractmethod
    def write_error_L000E(self, bitmap):
        pass

    @abstractmethod
    def write_error_L000F(self, bitmap):
        pass

    @abstractmethod
    def write_throttle(self, adc_value):
        pass

    @abstractmethod
    def write_map(self, adc_value):
        pass

    @abstractmethod
    def write_aap(self, adc_value):
        pass

    @abstractmethod
    def write_coolant_temp(self, temp_celsius):
        pass

    @abstractmethod
    def write_air_temp(self, temp_celsius):
        pass

    @abstractmethod
    def write_battery_voltage(self, volts):
        pass

    @abstractmethod
    def write_portg(self, bitmap):
        pass

    @abstractmethod
    def write_crankref_start(self, timestamp):
        pass

    @abstractmethod
    def write_crankref_id(self, crank_id):
        pass

    @abstractmethod
    def write_camshaft(self, timestamp):
        pass

    @abstractmethod
    def write_cam_error(self, error_code):
        pass

    @abstractmethod
    def write_spark_x1(self, timestamp):
        pass

    @abstractmethod
    def write_spark_x2(self, timestamp):
        pass

    @abstractmethod
    def write_nospark(self, error_code):
        pass

    @abstractmethod
    def write_eprom_load_name(self, name):
        pass

    @abstractmethod
    def write_eprom_load_addr(self, address):
        pass

    @abstractmethod
    def write_eprom_load_len(self, length):
        pass

    @abstractmethod
    def write_eprom_load_err(self, error_code):
        pass

    @abstractmethod
    def write_gps_time(self, csecs, secs, mins, hours, date, month, year):
        pass

    @abstractmethod
    def write_gps_fix_type(self, fix_type):
        pass

    @abstractmethod
    def write_gps_position(self, latitude, longitude):
        pass

    @abstractmethod
    def write_gps_velocity(self, velocity_mph):
        pass

    @abstractmethod
    def write_fs_write_time(self, milliseconds):
        pass

    @abstractmethod
    def write_fs_sync_time(self, milliseconds):
        pass

# ================================================================================================
# HDF5 Writer Class - Simplified implementation
# ================================================================================================

class HDF5Writer:
    """Writes decoded log data to HDF5 format with chunking and compression.

    NOTE: Time tracking is now handled by external TimeKeeper instance.
    This class is responsible only for writing data to HDF5 datasets.
    """

    def __init__(self, filename, L, timekeeper):
        """Initialize HDF5 writer.

        Args:
            filename: Output HDF5 filename
            L: Logsyms class reference
            timekeeper: TimeKeeper instance for time tracking
        """
        if not HDF5_AVAILABLE:
            raise ImportError("h5py and numpy are required for HDF5 output. Please install them.")

        self.filename = filename
        self.L = L
        self.timekeeper = timekeeper  # Use external TimeKeeper
        self.h5file = None
        self.datasets = {}

        # Buffering for performance (write in batches instead of one row at a time)
        self.buffers = {}  # dataset_name -> list of data rows
        self.buffer_size = 10000  # Flush buffer every N rows

        # Metadata tracking
        self.log_version_ecu = None
        self.log_version_ep = None
        self.log_version_wp = None
        self.eprom_loads = []  # List of (name, addr, len, err) tuples
        self.current_eprom_name = ""
        self.current_eprom_addr = None
        self.current_eprom_len = None

        # GPS back-calculation
        self.gps_sync_time_ns = None
        self.gps_first_time = None  # (csecs, secs, mins, hours, date, month, year)

        # Prospective timestamp warnings (deprecated - will be removed)
        self.prospective_past_warning_count = 0  # Prospective timestamps in the past

        # Pending injector events for pairing ON+duration into combined bar datasets
        self.pending_front_inj = None  # (time_ns, on_value) waiting for duration
        self.pending_rear_inj = None   # (time_ns, on_value) waiting for duration

        # Pending coil events for pairing ON+OFF into combined bar datasets
        self.pending_front_coil = None  # (time_ns, on_value) waiting for OFF
        self.pending_front_coil_manual = None  # (time_ns, on_value) waiting for OFF
        self.pending_rear_coil = None  # (time_ns, on_value) waiting for OFF
        self.pending_rear_coil_manual = None  # (time_ns, on_value) waiting for OFF

    def open(self):
        """Open HDF5 file and create resizable datasets with chunking."""
        self.h5file = h5py.File(self.filename, 'w')

        # Define chunk size (approximately 1 second of data ~1000 samples)
        chunk_1d = (1000,)
        chunk_2d = (1000, 2)
        chunk_3d = (1000, 3)

        # Create all datasets as resizable with compression
        # Format: (time_ns, value) pairs for most datasets
        ds_opts = {'maxshape': (None, 2), 'chunks': chunk_2d, 'compression': 'gzip', 'compression_opts': 4}
        ds_opts_1d = {'maxshape': (None,), 'chunks': chunk_1d, 'compression': 'gzip', 'compression_opts': 4}
        ds_opts_3d = {'maxshape': (None, 3), 'chunks': chunk_3d, 'compression': 'gzip', 'compression_opts': 4}

        # Engine timing (OFLO/HOFLO removed - used only for time tracking, not data logging)
        self.datasets['ecu_crankref_timestamp'] = self.h5file.create_dataset('ecu_crankref_timestamp', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_crankref_id'] = self.h5file.create_dataset('ecu_crankref_id', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_camshaft_timestamp'] = self.h5file.create_dataset('ecu_camshaft_timestamp', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_cam_error'] = self.h5file.create_dataset('ecu_cam_error', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rpm_instantaneous'] = self.h5file.create_dataset('ecu_rpm_instantaneous', (0, 2), dtype='float64', **ds_opts)
        self.datasets['ecu_rpm_smoothed'] = self.h5file.create_dataset('ecu_rpm_smoothed', (0, 2), dtype='float64', **ds_opts)

        # Combined injector bar datasets (Phase 3+)
        # Legacy separate ON/duration datasets removed - only combined format now
        # Format: (time_ns, duration_ticks) - time is actual ON time, duration in timer ticks (2μs per tick)
        ds_opts_bar = {'maxshape': (None, 2), 'chunks': chunk_2d, 'compression': 'gzip', 'compression_opts': 4}
        self.datasets['ecu_front_inj'] = self.h5file.create_dataset('ecu_front_inj', (0, 2), dtype='uint64', **ds_opts_bar)
        self.datasets['ecu_rear_inj'] = self.h5file.create_dataset('ecu_rear_inj', (0, 2), dtype='uint64', **ds_opts_bar)

        # Combined coil bar datasets (Phase 5+)
        # Format: (on_time_ns, duration_ns) - time is actual ON time, duration calculated from ON-to-OFF
        self.datasets['ecu_front_coil_bar'] = self.h5file.create_dataset('ecu_front_coil_bar', (0, 2), dtype='uint64', **ds_opts_bar)
        self.datasets['ecu_front_coil_manual_bar'] = self.h5file.create_dataset('ecu_front_coil_manual_bar', (0, 2), dtype='uint64', **ds_opts_bar)
        self.datasets['ecu_rear_coil_bar'] = self.h5file.create_dataset('ecu_rear_coil_bar', (0, 2), dtype='uint64', **ds_opts_bar)
        self.datasets['ecu_rear_coil_manual_bar'] = self.h5file.create_dataset('ecu_rear_coil_manual_bar', (0, 2), dtype='uint64', **ds_opts_bar)

        # Ignition - dual events for prospective timestamps
        self.datasets['ecu_front_coil_on_calc'] = self.h5file.create_dataset('ecu_front_coil_on_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_front_coil_on_actual'] = self.h5file.create_dataset('ecu_front_coil_on_actual', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_front_coil_off_calc'] = self.h5file.create_dataset('ecu_front_coil_off_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_front_coil_off_actual'] = self.h5file.create_dataset('ecu_front_coil_off_actual', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_front_ign_delay'] = self.h5file.create_dataset('ecu_front_ign_delay', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_front_coil_manual_on_calc'] = self.h5file.create_dataset('ecu_front_coil_manual_on_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_front_coil_manual_on_actual'] = self.h5file.create_dataset('ecu_front_coil_manual_on_actual', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_front_coil_manual_off_calc'] = self.h5file.create_dataset('ecu_front_coil_manual_off_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_front_coil_manual_off_actual'] = self.h5file.create_dataset('ecu_front_coil_manual_off_actual', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_coil_on_calc'] = self.h5file.create_dataset('ecu_rear_coil_on_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_coil_on_actual'] = self.h5file.create_dataset('ecu_rear_coil_on_actual', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_coil_off_calc'] = self.h5file.create_dataset('ecu_rear_coil_off_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_coil_off_actual'] = self.h5file.create_dataset('ecu_rear_coil_off_actual', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_ign_delay'] = self.h5file.create_dataset('ecu_rear_ign_delay', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_rear_coil_manual_on_calc'] = self.h5file.create_dataset('ecu_rear_coil_manual_on_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_coil_manual_on_actual'] = self.h5file.create_dataset('ecu_rear_coil_manual_on_actual', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_coil_manual_off_calc'] = self.h5file.create_dataset('ecu_rear_coil_manual_off_calc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_rear_coil_manual_off_actual'] = self.h5file.create_dataset('ecu_rear_coil_manual_off_actual', (0, 2), dtype='uint64', **ds_opts)

        # Spark events
        self.datasets['ecu_spark_x1'] = self.h5file.create_dataset('ecu_spark_x1', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_spark_x2'] = self.h5file.create_dataset('ecu_spark_x2', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_nospark'] = self.h5file.create_dataset('ecu_nospark', (0, 2), dtype='uint64', **ds_opts)

        # Spark advance (degrees BTDC) - separate streams per cylinder
        self.datasets['ecu_spark_front_x1_advance'] = self.h5file.create_dataset('ecu_spark_front_x1_advance', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_spark_front_x2_advance'] = self.h5file.create_dataset('ecu_spark_front_x2_advance', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_spark_rear_x1_advance'] = self.h5file.create_dataset('ecu_spark_rear_x1_advance', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_spark_rear_x2_advance'] = self.h5file.create_dataset('ecu_spark_rear_x2_advance', (0, 2), dtype='float32', **ds_opts)

        # Sensors
        self.datasets['ecu_throttle_adc'] = self.h5file.create_dataset('ecu_throttle_adc', (0, 2), dtype='uint64', **ds_opts)
        self.datasets['ecu_map_kpa'] = self.h5file.create_dataset('ecu_map_kpa', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_aap_kpa'] = self.h5file.create_dataset('ecu_aap_kpa', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_coolant_temp_c'] = self.h5file.create_dataset('ecu_coolant_temp_c', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_air_temp_c'] = self.h5file.create_dataset('ecu_air_temp_c', (0, 2), dtype='float32', **ds_opts)
        self.datasets['ecu_battery_voltage_v'] = self.h5file.create_dataset('ecu_battery_voltage_v', (0, 2), dtype='float32', **ds_opts)

        # System state
        self.datasets['ecu_fuel_pump'] = self.h5file.create_dataset('ecu_fuel_pump', (0, 2), dtype='uint8', **ds_opts)
        self.datasets['ecu_portg_debug'] = self.h5file.create_dataset('ecu_portg_debug', (0, 2), dtype='uint8', **ds_opts)

        # Errors (4 separate datasets)
        self.datasets['ecu_error_L000C'] = self.h5file.create_dataset('ecu_error_L000C', (0, 2), dtype='uint8', **ds_opts)
        self.datasets['ecu_error_L000D'] = self.h5file.create_dataset('ecu_error_L000D', (0, 2), dtype='uint8', **ds_opts)
        self.datasets['ecu_error_L000E'] = self.h5file.create_dataset('ecu_error_L000E', (0, 2), dtype='uint8', **ds_opts)
        self.datasets['ecu_error_L000F'] = self.h5file.create_dataset('ecu_error_L000F', (0, 2), dtype='uint8', **ds_opts)

        # Marker events (1D timestamp arrays)
        self.datasets['ecu_marker_5ms'] = self.h5file.create_dataset('ecu_marker_5ms', (0,), dtype='uint64', **ds_opts_1d)
        self.datasets['ecu_marker_p6_max'] = self.h5file.create_dataset('ecu_marker_p6_max', (0,), dtype='uint64', **ds_opts_1d)

        # CPU events
        self.datasets['ecu_cpu_event'] = self.h5file.create_dataset('ecu_cpu_event', (0, 2), dtype='uint8', **ds_opts)
        self.datasets['ecu_l4000_event'] = self.h5file.create_dataset('ecu_l4000_event', (0, 2), dtype='uint8', **ds_opts)

        # GPS (compound type for position)
        self.datasets['gps_position'] = self.h5file.create_dataset('gps_position', (0, 3), dtype='float64', **ds_opts_3d)  # (time_ns, lat, lon)
        self.datasets['gps_velocity_mph'] = self.h5file.create_dataset('gps_velocity_mph', (0, 2), dtype='float32', **ds_opts)
        self.datasets['gps_fix_type'] = self.h5file.create_dataset('gps_fix_type', (0, 2), dtype='uint8', **ds_opts)

        # Filesystem performance
        self.datasets['wp_fs_write_time_ms'] = self.h5file.create_dataset('wp_fs_write_time_ms', (0, 2), dtype='uint16', **ds_opts)
        self.datasets['wp_fs_sync_time_ms'] = self.h5file.create_dataset('wp_fs_sync_time_ms', (0, 2), dtype='uint16', **ds_opts)

    def append_data(self, dataset_name, data):
        """Append data to a resizable dataset (buffered for performance).

        Args:
            dataset_name: Name of the dataset
            data: Numpy array or list to append (should be [time_ns, value] pair)
        """
        if dataset_name not in self.datasets:
            return

        # Add to buffer
        if dataset_name not in self.buffers:
            self.buffers[dataset_name] = []

        self.buffers[dataset_name].append(data)

        # Flush buffer if it reaches the threshold
        if len(self.buffers[dataset_name]) >= self.buffer_size:
            self._flush_buffer(dataset_name)

    def _flush_buffer(self, dataset_name):
        """Flush buffered data for a specific dataset to HDF5 file.

        Args:
            dataset_name: Name of the dataset to flush
        """
        if dataset_name not in self.buffers or not self.buffers[dataset_name]:
            return

        ds = self.datasets[dataset_name]
        buffer_data = np.array(self.buffers[dataset_name])

        # Resize once for entire buffer
        old_size = ds.shape[0]
        new_size = old_size + len(buffer_data)
        ds.resize(new_size, axis=0)

        # Write all buffered data at once
        ds[old_size:new_size] = buffer_data

        # Clear buffer
        self.buffers[dataset_name] = []

    def append_injector_on(self, injector, time_ns, on_value):
        """Record injector ON event, waiting for duration to create combined bar.

        Args:
            injector: 'front' or 'rear'
            time_ns: Timestamp in nanoseconds
            on_value: ON event value (not currently used, but kept for compatibility)
        """
        if injector == 'front':
            self.pending_front_inj = (time_ns, on_value)
        elif injector == 'rear':
            self.pending_rear_inj = (time_ns, on_value)

    def append_injector_duration(self, injector, duration_ticks):
        """Record injector duration, pair with pending ON event to create combined bar.

        Args:
            injector: 'front' or 'rear'
            duration_ticks: Duration in timer ticks (2μs per tick)
        """
        if injector == 'front':
            if self.pending_front_inj is not None:
                time_ns, on_value = self.pending_front_inj
                # Create combined bar record: [time_ns, duration_ticks]
                self.append_data('ecu_front_inj', [time_ns, duration_ticks])
                self.pending_front_inj = None
        elif injector == 'rear':
            if self.pending_rear_inj is not None:
                time_ns, on_value = self.pending_rear_inj
                # Create combined bar record: [time_ns, duration_ticks]
                self.append_data('ecu_rear_inj', [time_ns, duration_ticks])
                self.pending_rear_inj = None

    def append_coil_on(self, coil, time_ns, on_value):
        """Record coil ON event, waiting for OFF to create combined bar.

        Args:
            coil: 'front_coil', 'front_coil_manual', 'rear_coil', or 'rear_coil_manual'
            time_ns: Timestamp in nanoseconds
            on_value: ON event value (not currently used, but kept for compatibility)
        """
        if coil == 'front_coil':
            self.pending_front_coil = (time_ns, on_value)
        elif coil == 'front_coil_manual':
            self.pending_front_coil_manual = (time_ns, on_value)
        elif coil == 'rear_coil':
            self.pending_rear_coil = (time_ns, on_value)
        elif coil == 'rear_coil_manual':
            self.pending_rear_coil_manual = (time_ns, on_value)

    def append_coil_off(self, coil, off_time_ns):
        """Record coil OFF event, pair with pending ON event to create combined bar.

        Args:
            coil: 'front_coil', 'front_coil_manual', 'rear_coil', or 'rear_coil_manual'
            off_time_ns: OFF event timestamp in nanoseconds
        """
        if coil == 'front_coil':
            if self.pending_front_coil is not None:
                on_time_ns, on_value = self.pending_front_coil
                duration_ns = off_time_ns - on_time_ns
                if duration_ns > 0:  # Sanity check
                    self.append_data('ecu_front_coil_bar', [on_time_ns, duration_ns])
                self.pending_front_coil = None
        elif coil == 'front_coil_manual':
            if self.pending_front_coil_manual is not None:
                on_time_ns, on_value = self.pending_front_coil_manual
                duration_ns = off_time_ns - on_time_ns
                if duration_ns > 0:
                    self.append_data('ecu_front_coil_manual_bar', [on_time_ns, duration_ns])
                self.pending_front_coil_manual = None
        elif coil == 'rear_coil':
            if self.pending_rear_coil is not None:
                on_time_ns, on_value = self.pending_rear_coil
                duration_ns = off_time_ns - on_time_ns
                if duration_ns > 0:
                    self.append_data('ecu_rear_coil_bar', [on_time_ns, duration_ns])
                self.pending_rear_coil = None
        elif coil == 'rear_coil_manual':
            if self.pending_rear_coil_manual is not None:
                on_time_ns, on_value = self.pending_rear_coil_manual
                duration_ns = off_time_ns - on_time_ns
                if duration_ns > 0:
                    self.append_data('ecu_rear_coil_manual_bar', [on_time_ns, duration_ns])
                self.pending_rear_coil_manual = None

    def close(self):
        """Write metadata and close HDF5 file."""
        if self.h5file is None:
            return

        # Flush all remaining buffered data before closing
        for dataset_name in list(self.buffers.keys()):
            self._flush_buffer(dataset_name)

        # Write metadata as root attributes
        if self.log_version_ecu is not None:
            self.h5file.attrs['log_version_ecu'] = self.log_version_ecu
        if self.log_version_ep is not None:
            self.h5file.attrs['log_version_ep'] = self.log_version_ep
        if self.log_version_wp is not None:
            self.h5file.attrs['log_version_wp'] = self.log_version_wp

        # GPS sync timing
        if self.gps_sync_time_ns is not None:
            self.h5file.attrs['gps_sync_elapsed_ns'] = self.gps_sync_time_ns

        # Back-calculated start time
        if self.gps_first_time and self.gps_sync_time_ns is not None:
            csecs, secs, mins, hours, date, month, year = self.gps_first_time
            # Create UTC timestamp from GPS time
            gps_dt = datetime(2000 + year, month, date, hours, mins, secs, csecs * 10000, tzinfo=timezone.utc)
            gps_unix = gps_dt.timestamp()
            # Back-calculate log start time
            log_start_unix = gps_unix - (self.gps_sync_time_ns / 1e9)
            self.h5file.attrs['log_start_timestamp_utc'] = log_start_unix
            self.h5file.attrs['log_start_timestamp_iso'] = datetime.fromtimestamp(log_start_unix, tz=timezone.utc).isoformat()

        # EPROM loads as a dataset (not attribute, to avoid VLEN string issues)
        if self.eprom_loads:
            dt = np.dtype([('name', 'S64'), ('address', np.uint16), ('length', np.uint16), ('error_status', np.uint8)])
            eprom_array = np.array(self.eprom_loads, dtype=dt)
            # Create a dataset for EPROM loads instead of an attribute
            self.h5file.create_dataset('eprom_loads', data=eprom_array, dtype=dt)

        self.h5file.close()
        self.h5file = None

# ================================================================================================
# Global variables (legacy - to be refactored)
# ================================================================================================

headingsPrinted = False
msb = 0
msb_id = -1

cr_ts = -1
fc_off = 0
rc_off = 0
map = -1
aap = -1
vm_V = -1
vta = -1
vtaPrev = -1
cr_ts_prev = -1
elapsed = -1
cridPrev = -1
crid = -1
epromIdString = ""
currentEpromId = epromIdString
rpm_avg = 0.0
secs=-1

fi_on = -1
ri_on = -1
ri_dur = 0
fi_dur = 0

showBinData = True
address = 0
current_record_hex = ""
current_record_address = 0

# Track the max difference between the two methods of converting thermistor readings to temperatures
maxDiff = 0.0

from collections import deque
# Store last 13 crank timestamps (64-bit ns) for smoothed RPM calculation
# 12 intervals = 2 full rotations (360°). Using ns timestamps avoids 16-bit overflow at low RPM.
crank_ts_history = deque(maxlen=13)

# ================================================================================================
# TimeKeeper Class - Simplified time tracking system
# ================================================================================================

class TimeKeeper:
    """Manages 64-bit nanosecond time tracking with wraparound detection.

    Implements the time tracking requirements:
    - 64-bit nanosecond counter starting at 0
    - 16-bit timer (2µs per tick) wraparound detection
    - Retrospective spark timestamp calculation
    - CRANKREF_ID state tracking
    """

    # Constants
    TICKS_TO_NS = 2000              # 2µs per tick
    TIMER_MAX = 65536               # 16-bit wraparound point

    # CRID timestamp offset from true TDC
    # The CRID markers are offset by 12° from true crankshaft TDC
    # This value should be added to calculated advance to get true advance
    CRID_TDC_OFFSET_DEGREES = 12.0  # degrees BTDC offset

    # Spark timing correction
    # There is a delay between when the spark is scheduled by the firmware and when
    # it is observed/logged. We need to account for this delay to determine when the
    # firmware actually scheduled the spark event.
    SPARK_DELAY_X1_TICKS = 7   # Timer ticks delay for SPRK1 (7 * 2μs = 14μs)
    SPARK_DELAY_X2_TICKS = 15  # Timer ticks delay for SPRK2 (15 * 2μs = 30μs)

    def __init__(self, verbose=False):
        """Initialize time tracking.

        Args:
            verbose: Enable verbose logging for errors
        """
        # Time tracking - start at 0 as if first _TS was 0x0000
        self.time_ns = 0
        self.prev_ts = 0

        # State tracking
        self.crankref_id = None  # Current CRANKREF_ID value
        self.crid_changed = False  # Flag to track when CRID changes

        # CR timestamp tracking for spark advance calculation
        # Stores the raw timestamp for each CRID (0-11)
        self.cr_timestamps = [None] * 12  # Array indexed by CRID
        # Validity flags for each CRID timestamp (invalidated after use)
        self.cr_timestamps_valid = [False] * 12
        # Track which CRID was last seen before each CRID (for sequence validation)
        self.cr_prev_crid = [None] * 12  # cr_prev_crid[5] = CRID seen before CRID 5

        # Spark detection filtering - only process first spark after CRID change
        self.spark_x1_seen_this_crid = False
        self.spark_x2_seen_this_crid = False

        # Store spark timestamps for advance calculation (populated during CR4-5 or CR9-10)
        self.pending_spark1_ts = None
        self.pending_spark1_time_ns = None
        self.pending_spark2_ts = None
        self.pending_spark2_time_ns = None

        # GPS PPS tracking for timer accuracy verification
        self.first_pps_time_ns = None    # Time of first PPS event
        self.last_pps_time_ns = None     # Time of most recent PPS event
        self.pps_count = 0               # Number of PPS events seen

        # Configuration
        self.verbose = verbose

    def process_ts_event(self, raw_ts, is_oflo=False, is_hoflo=False):
        """Process a _TS (retrospective timestamp) event and advance time.

        Rollover is detected by checking sign bits of consecutive timestamps:
        - If prev_ts[15]==1 and raw_ts[15]==0: rollover occurred
        - Otherwise: no rollover

        Special OFLO handling:
        - If OFLO event is seen but sign-bit check indicates NO rollover,
          the OFLO must be completely ignored (stale prediction).

        Args:
            raw_ts: Raw 16-bit timestamp value
            is_oflo: True if this is LOGID_ECU_T1_OFLO_TYPE_TS (optional hint)
            is_hoflo: True if this is LOGID_ECU_T1_HOFLO_TYPE_TS (optional hint)

        Returns:
            Current absolute time in nanoseconds
        """
        # Check sign bits for rollover detection
        prev_sign_bit = (self.prev_ts >> 15) & 1
        curr_sign_bit = (raw_ts >> 15) & 1
        rollover_occurred = (prev_sign_bit == 1) and (curr_sign_bit == 0)

        # Special case: OFLO event with no actual rollover must be ignored
        if is_oflo and not rollover_occurred:
            # Stale OFLO prediction - do not update time or prev_ts
            return self.time_ns

        # Calculate delta from previous timestamp
        delta_ticks = raw_ts - self.prev_ts

        # Handle wraparound if rollover detected
        if rollover_occurred:
            delta_ticks += self.TIMER_MAX

        # Advance time
        self.time_ns += delta_ticks * self.TICKS_TO_NS
        self.prev_ts = raw_ts

        return self.time_ns

    def process_retrospective_t_event(self, raw_ts):
        """Process a _TYPE_PTS event (prescriptive timestamp - spark timestamp from the past).

        Spark events report timestamps of sparks that already occurred.
        They are guaranteed to be in the past, within the previous timer cycle.

        Args:
            raw_ts: Raw 16-bit timestamp value

        Returns:
            Absolute time in nanoseconds when the spark actually occurred
        """
        # Calculate signed delta from current timestamp
        delta_ticks = raw_ts - self.prev_ts

        # If delta appears positive and large (>32768), it's actually from the past
        # (wrapped around the timer)
        if delta_ticks > 32768:
            delta_ticks -= self.TIMER_MAX

        # Calculate absolute time when spark occurred
        spark_time_ns = self.time_ns + (delta_ticks * self.TICKS_TO_NS)

        return spark_time_ns

    def advance_time_by_ns(self, ns):
        """Advance time by a fixed number of nanoseconds (for non-timestamped events).

        Args:
            ns: Nanoseconds to advance (typically 1)

        Returns:
            Current absolute time in nanoseconds
        """
        self.time_ns += ns
        return self.time_ns

    def get_time_ns(self):
        """Get current absolute time in nanoseconds."""
        return self.time_ns

    def get_time_sec(self):
        """Get current absolute time in seconds."""
        return self.time_ns / 1e9

    def set_time_ns(self, time_ns):
        """Set absolute time in nanoseconds (used to revert time on backwards adjustment)."""
        self.time_ns = time_ns

    def try_update_timer_bits(self, upper_6_bits):
        """Try to update time using upper 6 bits of 16-bit timer.

        Args:
            upper_6_bits: Upper 6 bits of the 16-bit timer (bits 10-15)

        Returns:
            True if time was advanced, False if update would cause time to go backwards
        """
        # Construct the target timer value using the upper 6 bits and current prev_ts lower 10 bits
        target_timer = (upper_6_bits << 10) | (self.prev_ts & 0x3FF)

        # Calculate delta from current prev_ts
        delta_ticks = target_timer - self.prev_ts

        # Handle potential wraparound
        if delta_ticks < 0:
            delta_ticks += self.TIMER_MAX

        # Only advance if delta is positive and reasonable (not backwards in time)
        if delta_ticks > 0 and delta_ticks < self.TIMER_MAX // 2:
            # This looks like a forward time advancement
            self.time_ns += delta_ticks * self.TICKS_TO_NS
            self.prev_ts = target_timer
            return True

        # Would go backwards or delta is unreasonable, ignore
        return False

    def set_crankref_id(self, crid):
        """Update CRANKREF_ID state and reset spark detection flags."""
        self.crankref_id = crid
        # Reset spark flags when entering a spark window (CR4 for front, CR9 for rear)
        # This allows first SPRK1 and first SPRK2 to be logged in each window
        if crid == 4:
            # Entering front cylinder spark window (CR4-CR5)
            self.spark_x1_seen_this_crid = False
            self.spark_x2_seen_this_crid = False
        elif crid == 9:
            # Entering rear cylinder spark window (CR9-CR10)
            self.spark_x1_seen_this_crid = False
            self.spark_x2_seen_this_crid = False

    def process_pps_event(self):
        """Process GPS PPS (Pulse Per Second) event.

        Tracks PPS events and verifies ECU timer accuracy against GPS time.
        GPS PPS marks the start of a new UTC second and is highly accurate.

        Returns:
            String with statistics to print, or None for first PPS
        """
        current_time_ns = self.time_ns
        self.pps_count += 1

        if self.first_pps_time_ns is None:
            # First PPS - establish baseline
            self.first_pps_time_ns = current_time_ns
            self.last_pps_time_ns = current_time_ns
            return None  # No stats for first PPS

        # Calculate elapsed time since last PPS and since first PPS
        ns_since_last_pps = current_time_ns - self.last_pps_time_ns
        ns_since_first_pps = current_time_ns - self.first_pps_time_ns

        # Convert to seconds
        sec_since_last_pps = ns_since_last_pps / 1e9
        sec_since_first_pps = ns_since_first_pps / 1e9

        # Expected seconds (integer values since PPS marks whole seconds)
        expected_sec_since_last = round(sec_since_last_pps)
        expected_sec_since_first = self.pps_count - 1  # First PPS is at index 0

        # Calculate errors
        error_since_last_ns = ns_since_last_pps - (expected_sec_since_last * 1e9)
        error_since_first_ns = ns_since_first_pps - (expected_sec_since_first * 1e9)

        # Calculate PPM (parts per million) errors
        ppm_since_last = (error_since_last_ns / (expected_sec_since_last * 1e9)) * 1e6 if expected_sec_since_last > 0 else 0
        ppm_since_first = (error_since_first_ns / (expected_sec_since_first * 1e9)) * 1e6 if expected_sec_since_first > 0 else 0

        # Update last PPS time
        self.last_pps_time_ns = current_time_ns

        # Format statistics
        stats = (f"GPS_PPS: Δlast: {sec_since_last_pps:.6f}s "
                f"(expect {expected_sec_since_last}s, err: {error_since_last_ns:+.0f}ns, {ppm_since_last:+.1f}ppm) | "
                f"Δfirst: {sec_since_first_pps:.6f}s "
                f"(expect {expected_sec_since_first}s, err: {error_since_first_ns:+.0f}ns, {ppm_since_first:+.1f}ppm)")

        return stats

    def get_crankref_id(self):
        """Get current CRANKREF_ID value."""
        return self.crankref_id

    def set_cr_timestamp(self, crid, raw_ts):
        """Store the raw timestamp for a CRID and mark it as valid.

        Args:
            crid: Crankref ID (0-11)
            raw_ts: Raw 16-bit timestamp value
        """
        if 0 <= crid < 12:
            self.cr_timestamps[crid] = raw_ts
            self.cr_timestamps_valid[crid] = True
            # Track what the previous CRID was before this one
            self.cr_prev_crid[crid] = self.crankref_id

    def is_spark_in_valid_crid(self):
        """Check if current CRID is valid for spark events.

        Both SPRK1 and SPRK2 fire in the same CRID windows (dual-plug per cylinder):
        - Front cylinder: CR4-CR5 (60° BTDC to TDC)
        - Rear cylinder: CR9-CR10 (60° BTDC to TDC)

        Returns:
            Tuple of (is_valid, is_front_cylinder):
            - is_valid: True if CRID is in a valid spark window
            - is_front_cylinder: True if in front cylinder window (CR4-5),
                                 False if in rear cylinder window (CR9-10),
                                 None if not in any valid window
        """
        if self.crankref_id is None:
            return (False, None)

        if 4 <= self.crankref_id <= 5:
            # Front cylinder window - both SPRK1 and SPRK2 fire here
            return (True, True)
        elif 9 <= self.crankref_id <= 10:
            # Rear cylinder window - both SPRK1 and SPRK2 fire here
            return (True, False)
        else:
            # Not in a valid spark window
            return (False, None)

    def calculate_spark_advance(self, spark_pts, is_front_cylinder):
        """Calculate spark advance in degrees BTDC.

        Formula:
        - Front cylinder (X1): CR5 is TDC, CR4 is 60° BTDC
            advance = (CR5_TS - SPARK_PTS) * 60 / (CR5_TS - CR4_TS)
        - Rear cylinder (X2): CR10 is TDC, CR9 is 60° BTDC
            advance = (CR10_TS - SPARK_PTS) * 60 / (CR10_TS - CR9_TS)

        Args:
            spark_pts: Raw spark timestamp (PTS)
            is_front_cylinder: True for X1 (front), False for X2 (rear)

        Returns:
            Spark advance in degrees BTDC, or None if cannot be calculated
        """
        if is_front_cylinder:
            # Front cylinder: CR5 is TDC (0° BTDC), CR4 is 60° BTDC
            ref_crid = 5  # TDC (0°)
            prev_crid = 4  # 60° BTDC
        else:
            # Rear cylinder: CR10 is TDC (0° BTDC), CR9 is 60° BTDC
            ref_crid = 10  # TDC (0°)
            prev_crid = 9  # 60° BTDC

        # Check if we have the required CR timestamps
        ref_ts = self.cr_timestamps[ref_crid]
        prev_ts = self.cr_timestamps[prev_crid]

        if ref_ts is None or prev_ts is None:
            return None

        # Validate CRID sequence: CR4 must come before CR5, CR10 before CR11
        # CRIDs count sequentially: 0->1->2->...->11->0 (wrapping)
        crid_before_ref = self.cr_prev_crid[ref_crid]
        if crid_before_ref != prev_crid:
            # CRID sequence error - cannot trust the CR interval for calculation
            return None

        # Validate spark occurs within the CR interval: prev_ts <= spark_pts <= ref_ts
        # Calculate deltas with wraparound handling
        delta_ref_spark = ref_ts - spark_pts  # Distance from spark to reference CR
        delta_ref_prev = ref_ts - prev_ts     # Distance from previous to reference CR
        delta_spark_prev = spark_pts - prev_ts  # Distance from previous CR to spark

        # Handle timestamp wraparound (16-bit counter)
        if delta_ref_spark < 0:
            delta_ref_spark += 65536
        if delta_ref_prev <= 0:
            delta_ref_prev += 65536
        if delta_spark_prev < 0:
            delta_spark_prev += 65536

        # Sanity check on CR interval
        if delta_ref_prev == 0:
            return None

        # Verify spark is within the interval: prev_ts <= spark_pts <= ref_ts
        # This is true when both:
        # 1. (spark_pts - prev_ts) >= 0 and <= (ref_ts - prev_ts)
        # 2. (ref_ts - spark_pts) >= 0 and <= (ref_ts - prev_ts)
        if delta_spark_prev > delta_ref_prev:
            # Spark is before prev_ts - wrong interval
            return None
        if delta_ref_spark > delta_ref_prev:
            # Spark is after ref_ts - wrong interval
            return None

        # Calculate advance in degrees BTDC
        #
        # CR5 for front (CR10 for rear) is at TDC (0° BTDC)
        # CR4 for front (CR9 for rear) is 60° BTDC
        #
        # If spark occurs at CR5/CR10 time, advance = 0° BTDC (no advance - spark at TDC)
        # If spark occurs at CR4/CR9 time, advance = 60° BTDC (maximum advance - early spark)
        # If spark is halfway between, advance = 30° BTDC
        #
        # Formula: advance = (SPARK_PTS - CR4/CR9_TS) * 60 / (CR5/CR10_TS - CR4/CR9_TS)
        # This gives how far spark is AFTER CR4/CR9 (60° BTDC), scaled to degrees
        # Then we invert: 60 - value = degrees BTDC
        numerator = delta_spark_prev  # Distance from CR4/CR9 to spark
        denominator = delta_ref_prev  # Total interval (60°)

        # Calculate how far past CR4 the spark occurred, then convert to degrees BTDC
        advance = 60.0 - ((numerator * 60.0) / denominator)

        # Sanity check: typical motorcycle spark advance is 0-60° BTDC
        # Values above 60° are possible but unusual, values above 120° are almost certainly errors
        if advance < 0 or advance > 120:
            return None

        return advance

    def store_pending_spark(self, spark_pts, actual_time_ns, is_sprk1):
        """Store a spark timestamp for later advance calculation.

        Args:
            spark_pts: Raw spark timestamp
            actual_time_ns: Actual nanosecond time when spark occurred
            is_sprk1: True for SPRK1, False for SPRK2
        """
        if is_sprk1:
            self.pending_spark1_ts = spark_pts
            self.pending_spark1_time_ns = actual_time_ns
        else:
            self.pending_spark2_ts = spark_pts
            self.pending_spark2_time_ns = actual_time_ns

    def calculate_and_write_spark_advance(self, current_crid, h5_writer):
        """Calculate spark advance when CRID N+2 arrives.

        When CRID N+2 is detected:
        - If CRID N and N+1 timestamps are both valid, calculate spark advance
        - Invalidate CRID N and N+1 timestamps after use

        For front cylinder: N=4, so calculate at CR6
        For rear cylinder: N=9, so calculate at CR11

        Args:
            current_crid: The CRID that just arrived
            h5_writer: HDF5 writer for advance data (or None)

        Returns:
            Dictionary with 'spark1_advance' and 'spark2_advance' (or None if not calculated)
        """
        result = {'spark1_advance': None, 'spark2_advance': None}

        # Determine if this is CRID N+2 for either cylinder
        if current_crid == 6:
            # Front cylinder: CR6 = CR4+2
            n = 4
            n_plus_1 = 5
        elif current_crid == 11:
            # Rear cylinder: CR11 = CR9+2
            n = 9
            n_plus_1 = 10
        else:
            # Not a CRID N+2, nothing to calculate
            return result

        # Check if both CRID N and N+1 timestamps are valid
        if not (self.cr_timestamps_valid[n] and self.cr_timestamps_valid[n_plus_1]):
            # Can't calculate - invalidate and return
            self.cr_timestamps_valid[n] = False
            self.cr_timestamps_valid[n_plus_1] = False
            return result

        # Get timestamps
        cr_n_ts = self.cr_timestamps[n]
        cr_n_plus_1_ts = self.cr_timestamps[n_plus_1]

        # Calculate deltas with wraparound
        delta_interval = cr_n_plus_1_ts - cr_n_ts
        if delta_interval <= 0:
            delta_interval += 65536

        if delta_interval == 0:
            # Invalid interval
            self.cr_timestamps_valid[n] = False
            self.cr_timestamps_valid[n_plus_1] = False
            return result

        # Determine cylinder name for HDF5 stream names
        cyl_name_lower = 'front' if n == 4 else 'rear'

        # Calculate SPRK1 advance if we have it
        if self.pending_spark1_ts is not None:
            delta_spark = self.pending_spark1_ts - cr_n_ts
            if delta_spark < 0:
                delta_spark += 65536

            # Calculate base advance: 60 - (distance from N / interval) * 60
            advance = 60.0 - ((delta_spark * 60.0) / delta_interval)
            # Add TDC offset correction
            advance += self.CRID_TDC_OFFSET_DEGREES

            # Sanity check
            if 0 <= advance <= 120:
                result['spark1_advance'] = advance
                # Write to HDF5 with cylinder-specific stream name
                if h5_writer and self.pending_spark1_time_ns is not None:
                    stream_name = f'ecu_spark_{cyl_name_lower}_x1_advance'
                    h5_writer.append_data(stream_name, [self.pending_spark1_time_ns, advance])

        # Calculate SPRK2 advance if we have it
        if self.pending_spark2_ts is not None:
            delta_spark = self.pending_spark2_ts - cr_n_ts
            if delta_spark < 0:
                delta_spark += 65536

            # Calculate base advance: 60 - (distance from N / interval) * 60
            advance = 60.0 - ((delta_spark * 60.0) / delta_interval)
            # Add TDC offset correction
            advance += self.CRID_TDC_OFFSET_DEGREES

            # Sanity check
            if 0 <= advance <= 120:
                result['spark2_advance'] = advance
                # Write to HDF5 with cylinder-specific stream name
                if h5_writer and self.pending_spark2_time_ns is not None:
                    stream_name = f'ecu_spark_{cyl_name_lower}_x2_advance'
                    h5_writer.append_data(stream_name, [self.pending_spark2_time_ns, advance])

        # Invalidate CRID N and N+1 timestamps
        self.cr_timestamps_valid[n] = False
        self.cr_timestamps_valid[n_plus_1] = False

        # Clear pending sparks
        self.pending_spark1_ts = None
        self.pending_spark1_time_ns = None
        self.pending_spark2_ts = None
        self.pending_spark2_time_ns = None

        return result


# Global time tracking for human-readable output (OLD - to be replaced)
global_time_ns = 0
global_prev_timestamp = -1
global_in_upper_half = False  # Track which half of timer cycle we're in
gps_last_sec_time_ns = -1  # Track when we last saw a GPS SEC change
gps_first_sec_time_ns = -1  # Track when we saw the FIRST GPS SEC (for drift calculation)
gps_sec_count = 0  # Count of GPS SEC events seen

f=""

def update_global_time(has_timestamp=False, raw_timestamp=None, is_overflow=False, is_marker=False):
    """Update the global nanosecond counter for human-readable output.

    Args:
        has_timestamp: True if this event has a raw timestamp
        raw_timestamp: The raw 16-bit timestamp value (if has_timestamp=True)
        is_overflow: True if this is a T1_OFLO event (timer wrapped 65535→0, b15: 1→0)
        is_marker: True if this is a TIME_MARKER event (b15 went 0→1, timestamp ~32768)
    """
    global global_time_ns, global_prev_timestamp, global_in_upper_half

    if has_timestamp and raw_timestamp is not None:
        if global_prev_timestamp >= 0:
            delta_ticks = raw_timestamp - global_prev_timestamp

            if is_overflow:
                # OFLO: Timer wrapped. Timestamp is the counter value shortly after wrap.
                # Delta = (65536 - prev_timestamp) + raw_timestamp
                delta_ticks = (65536 - global_prev_timestamp) + raw_timestamp
                global_time_ns += delta_ticks * 2000
                global_prev_timestamp = raw_timestamp
                global_in_upper_half = False  # Now in lower half (timestamps 0-32767)
            # MARKER and all other timestamped events: calculate delta normally
            else:
                # Check if timestamp is in expected half of timer cycle
                ts_in_upper_half = (raw_timestamp >= 32768)

                # Handle negative delta (wraparound or out-of-order)
                if delta_ticks < 0:
                    # Could be wraparound or out-of-order
                    if ts_in_upper_half != global_in_upper_half:
                        # Crossing half boundary - add wraparound
                        delta_ticks += 65536
                    else:
                        # Same half, negative delta = out-of-order
                        # Don't advance time, don't update prev_timestamp
                        pass

                # Only advance time if we have positive delta
                if delta_ticks >= 0:
                    global_time_ns += delta_ticks * 2000
                    global_prev_timestamp = raw_timestamp
                    # Update half tracking
                    if is_marker:
                        global_in_upper_half = True  # MARKER indicates entry to upper half
                    else:
                        global_in_upper_half = ts_in_upper_half
        else:
            # First timestamp - initialize tracking
            global_prev_timestamp = raw_timestamp
            global_in_upper_half = (raw_timestamp >= 32768)
    else:
        global_time_ns += 1  # Untimestamped event

def fmt_record(recordCnt, timekeeper):
    """Format record number with elapsed time for human-readable output.

    Args:
        recordCnt: Record number
        timekeeper: TimeKeeper instance for time tracking

    Returns string like: "0x00000000: 03 00            [  123 @    45.6781s]:"
    or just "[  123 @    45.6781s]:" if showBinData is False.
    This matches the time shown in HDF5/visualization tools.
    """
    elapsed_sec = timekeeper.get_time_sec()
    hex_prefix = get_hex_prefix()
    return f"{hex_prefix}[{recordCnt:6} @ {elapsed_sec:10.4f}s]:"

def decodeL000C(byte):
    if (byte & 0x80):
        print(f"Bad CAM,", end="")
    if (byte & 0x40):
        print(f"Bad CRANK,", end="")
    if (byte & 0x20):
        print(f"Bad MAP,", end="")
    if (byte & 0x10):
        print(f"Bad AN2,", end="")
    if (byte & 0x08):
        print(f"Bad VTA,", end="")
    if (byte & 0x04):
        print(f"Bad THW,", end="")
    if (byte & 0x02):
        print(f"Bad THA,", end="")
    if (byte & 0x01):
        print(f"Bad AAP", end="")
    print()

# Decoding L000D and L000F are identical.
# L000D events can get "better" if the sensor comes back on-line,
# but L000F events are "sticky" until the ECU powers down again.
def decodeL000D(byte):
    if (byte & 0x80):
        print(f"?B7,", end="")
    if (byte & 0x40):
        print(f"?B6,", end="")
    if (byte & 0x20):
        print(f"?B5,", end="")
    if (byte & 0x10):
        print(f"Bad Rcoil1,", end="")
    if (byte & 0x08):
        print(f"Bad Rcoil2,", end="")
    if (byte & 0x04):
        print(f"Bad Fcoil1,", end="")
    if (byte & 0x02):
        print(f"Bad Fcoil2,", end="")
    if (byte & 0x01):
        print(f"Bad DON", end="")
    print()

# This function converts a raw 8-bit ADC reading of an Aprilia temperature sensor back to degrees C.
#
# An excellent calculator of NTC thermistor response can be found here:
#   https://www.thinksrs.com/downloads/programs/therm%20calc/ntccalibrator/ntccalculator.html
#
# This thermistor data was published in Aprilia's "Mille Training Manual":
#  - At 20 degrees centigrade the resistance must be about 2450 Ohms
#  - At 40 degrees centigrade the resistance must be about 1114 Ohms
#  - At 60 degrees centigrade the resistance must be about 584 Ohms
#  - At 90 degrees centigrade the resistance must be about 245 Ohms

def convertApriliaTempSensorAdcToDegC(adc):
    # Work backwards to get the voltage we must have measured.
    # Vref is nominally 5.0V, and the ADC is 8 bits (255 max value)
    Vref = 5.0
    Vmeas = adc * Vref / 255.0

    # Based on color code, Rtop (R751 or R781) is 2.70K 0.5% (red/violet/black/brown/green).
    # It measures out at 2.70K, so that is accurate.
    Rtop = 2700

    # Work out what the resistance of the thermistor must have been to generate the Voltage we measured
    Rntc = (Vmeas * Rtop) / (Vref - Vmeas)

    # Convert an NTC resistor to a temperature using the Beta method
    #
    # The Beta constant was calculated from the ntccalculator website, above
    # The resistances for the Beta calculation came from measurements of sensor resistances at 0C, 25C, and 90C.
    # I am making an assumption that the NTC resistor in the Aprilia sensor is rated 2K Ohms at 25C.
    # I measured it at 1992 Ohms at 25C. 2K is a standard NTC value, so this seems reasonable.
    R25 = 1992
    Beta = 3526
    degC_Beta = (1/((1/Beta)*math.log(Rntc/R25)+(1/(25+273.15))))-273.15

    # The Steinhart-Hart coefficients come from the same calculator website, as above
    # Resistance/temperature Measurements come from an experiment I ran a long time ago.
    # I will try to find that data and get it republished. In the meantime:
    A = 1.142579776e-3          # 5880 Ohms at 0C
    B = 2.941596847e-4          # 1992 Ohms at 25C
    C = -0.5305974726e-7        #  249 Ohms at 90C
    logR = math.log(Rntc)
    degC_SH = (1/(A + (B * logR) + (C * (logR**3)))) - 273.15

    global maxDiff
    diff = abs((degC_Beta - degC_SH))
    if diff > maxDiff:
        maxDiff = diff
    # print(f"beta: {degC_Beta:.1f}, SH: {degC_SH:.1f}")

    # Experiments show that S_H and Beta differ by about 1 degree at most, so it probably does not matter which
    # one to use. Nonetheless, the S-H method is known to be more accurate so we use it.
    return degC_SH


def convertPressureSensorAdcToKpa(adc_counts):
    """
    Convert Aprilia MAP/AAP pressure sensor ADC counts to kPa.

    Sensor output formula: Vo = Vcc * (0.006*Pi + 0.12)
    Solving for pressure: Pi = [Vo - (0.12*Vcc)] / (0.006*Vcc)
    Where Vo = (ADC/256) * Vref
    and Vref = Vcc = 5.0V

    Args:
        adc_counts: ADC value (0-255)

    Returns:
        Pressure in kPa (float)
    """
    Vref = 5.0
    Vo = (adc_counts / 256.0) * Vref
    pressure_kpa = (Vo - (0.12 * Vref)) / (0.006 * Vref)
    return pressure_kpa


def read(f, readCount, showAddress=False, newLine=True):
    global address
    global showBinData
    global current_record_hex
    global current_record_address

    try:
        bytes = f.read(readCount)
    except Exception as e:
        print(f"\nError reading from file at address {address:#x}: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        exit(1)

    if (showBinData):
        if (showAddress):
            # Start of new record - save address and reset hex accumulator
            current_record_address = address
            current_record_hex = ""

        # Accumulate hex bytes for this record
        for byte in bytes:
            current_record_hex += f"{byte:02X} "

    address += readCount
    return bytes

def get_hex_prefix():
    """Return formatted hex prefix for current record (address + padded hex bytes).

    Returns string like: "0x00000000: 03 00           "
    Pads to width of 4 bytes (12 chars for hex: "XX XX XX XX ")
    """
    global current_record_hex
    global current_record_address
    global showBinData

    if not showBinData:
        return ""

    # Pad hex string to 4 bytes width (each byte is "XX ", so 12 chars total)
    hex_padded = current_record_hex.ljust(12)
    return f"0x{current_record_address:08X}: {hex_padded} "

def main():
    global cr_ts
    global fc_off
    global rc_off
    global aap
    global map
    global vm_V
    global vta
    global cr_ts_prev
    global elapsed
    global cridPrev
    global crid
    global epromIdString
    global currentEpromId
    global rpm_avg
    global secs
    global fi_on
    global ri_on
    global fi_dur
    global ri_dur

    # Create argument parser
    parser = argparse.ArgumentParser(description='Decode logs generated by the umod4 system.')
    parser.add_argument('logfile', help='Input log file to decode')
    parser.add_argument('-L', '--Logsyms', help='Path to directory containing a specific version of the Logsyms package (optional)')
    parser.add_argument('--format', choices=['hr', 'h5'], default='hr',
                        help='Output format: hr (human-readable, default) or h5 (hdf5)')
    parser.add_argument('-o', '--output', help='Output file (default: auto-generated from input filename)')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='Enable verbose logging for time tracking and reordering events')

    # Parse arguments
    args = parser.parse_args()

    # Auto-generate output filename if not specified
    if not args.output:
        # Replace .um4 extension if present, otherwise append
        base_name = args.logfile
        if base_name.lower().endswith('.um4'):
            base_name = base_name[:-4]  # Remove .um4

        if args.format == 'hr':
            args.output = base_name + '.hr'
        else:  # h5
            args.output = base_name + '.h5'

    # Validate arguments
    if args.format == 'h5':
        if not HDF5_AVAILABLE:
            parser.error("HDF5 format requires h5py and numpy. Please install them.")
        if not args.output.endswith('.h5') and not args.output.endswith('.hdf5'):
            print(f"Warning: HDF5 output file '{args.output}' does not have .h5 or .hdf5 extension", file=sys.stderr)

    # Initialize HDF5 writer if needed
    h5_writer = None
    if args.format == 'h5':
        # HDF5 format - we'll initialize the writer after loading Logsyms
        pass

    # Open output file or use stdout (for human-readable format)
    if args.format == 'hr' and args.output:
        try:
            output_file = open(args.output, 'w', encoding='utf-8')
            old_stdout = sys.stdout
            sys.stdout = output_file
        except Exception as e:
            print(f"Error opening output file: {e}")
            return 1
    elif args.format == 'h5':
        # For HDF5 output, suppress all stdout output
        output_file = open(os.devnull, 'w', encoding='utf-8')
        old_stdout = sys.stdout
        sys.stdout = output_file
    else:
        output_file = None

    # Import Logsyms - handle both Nuitka frozen binaries and normal Python execution
    # First check if Logsyms was already imported at module level (for Nuitka bundling)
    if LOGSYMS_PRELOADED:
        # Logsyms was successfully imported at module level
        ls = Logsyms
        L = ls.Logsyms
        print(f"# Logsyms preloaded at module level")
    else:
        # Logsyms not preloaded - detect runtime environment
        # Nuitka sets __compiled__ attribute on compiled modules/functions
        is_nuitka = hasattr(sys.modules[__name__], '__compiled__') or '__nuitka__' in dir(__builtins__)
        is_frozen = getattr(sys, 'frozen', False)  # PyInstaller, py2exe, cx_freeze

        if is_nuitka or is_frozen:
            # Running in a frozen/compiled binary but Logsyms wasn't preloaded
            print(f"FATAL ERROR: Running in compiled binary but Logsyms was not bundled", file=sys.stderr)
            print(f"This is a build error - Logsyms must be included during compilation", file=sys.stderr)
            print(f"Detection: nuitka={is_nuitka}, frozen={is_frozen}", file=sys.stderr)
            print(f"sys.path = {sys.path}", file=sys.stderr)
            print(f"Available modules: {sorted([m for m in sys.modules.keys() if not m.startswith('_')])[:20]}", file=sys.stderr)
            return 1
        else:
            # Running as normal Python script - need to find Logsyms in venv
            from pathlib import Path

            if args.Logsyms:
                # Use the path defined on the cmdline
                site_packages = args.Logsyms
            else:
                # Get the directory containing the current script
                script_dir = Path(__file__).parent.absolute()

                # Get an absolute path to the .venv
                venv_path = os.path.join(script_dir, "..", "..", "build", ".venv")

                # Use that to find where the packages live
                site_packages = os.path.join(venv_path, "lib", f"python{sys.version_info.major}.{sys.version_info.minor}", "site-packages")

            sys.path.insert(0, site_packages)
            print(f"# Logsyms imported from <${site_packages}>")

            # Import the package containing all the log symbol definitions
            try:
                import Logsyms as ls
                L = ls.Logsyms
            except ImportError as e:
                print(f"FATAL ERROR: Could not import Logsyms from {site_packages}: {e}", file=sys.stderr)
                print(f"Try building the project first with CMake to generate Logsyms", file=sys.stderr)
                return 1

    # Create TimeKeeper for time tracking (used by both human-readable and HDF5 output)
    timekeeper = TimeKeeper(verbose=args.verbose)

    # Initialize HDF5 writer now that we have Logsyms loaded
    if args.format == 'h5':
        h5_writer = HDF5Writer(args.output, L, timekeeper)
        h5_writer.open()
        print(f"# Writing HDF5 output to {args.output}")

    try:
        logfilename = args.logfile

        recordCnt = 0

        with open(logfilename, "rb") as f:

            while (True):
                b = read(f, 1, True)
                if (len(b) < 1):
                    break

                recordCnt = recordCnt+1

                byte = b[0]
                # Python does not have a useful equivalent of a C 'switch' statement, so we get a giant if-tree:
                if byte == L.LOGID_GEN_ECU_LOG_VER_TYPE_U8:
                    rd = read(f, L.LOGID_GEN_ECU_LOG_VER_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} ECU_VR: {rd[0]}")
                    if h5_writer:
                        h5_writer.log_version_ecu = rd[0]

                elif byte == L.LOGID_GEN_EP_LOG_VER_TYPE_U8:
                    rd = read(f, L.LOGID_GEN_EP_LOG_VER_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} EP_VR:  {rd[0]}")
                    if h5_writer:
                        h5_writer.log_version_ep = rd[0]

                elif byte == L.LOGID_GEN_WP_LOG_VER_TYPE_U8:
                    rd = read(f, L.LOGID_GEN_WP_LOG_VER_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} WP_VR:  {rd[0]}")
                    if h5_writer:
                        h5_writer.log_version_wp = rd[0]

                # Handle ECU events
                elif byte == L.LOGID_ECU_CPU_EVENT_TYPE_U8:
                    event = read(f, L.LOGID_ECU_CPU_EVENT_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} CPU:    {event}")
                    if h5_writer:
                        h5_writer.append_data('ecu_cpu_event', [timekeeper.get_time_ns(), event])

                elif byte == L.LOGID_ECU_T1_OFLO_TYPE_TS:
                    oflo_ts = int.from_bytes(read(f, L.LOGID_ECU_T1_OFLO_DLEN), byteorder='little', signed=False)
                    # RETROSPECTIVE timestamp - event HAS occurred, advance time_ns
                    # This is a timer overflow event, so mark it specially for wraparound handling
                    timekeeper.process_ts_event(oflo_ts, is_oflo=True)
                    print(f"{fmt_record(recordCnt, timekeeper)} OFLO_TS: {oflo_ts}")
                    # OFLO not written to HDF5 - used only for time tracking

                elif byte == L.LOGID_ECU_L4000_EVENT_TYPE_U8:
                    rd = read(f, L.LOGID_ECU_L4000_EVENT_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} L4000:  {rd[0]}")
                    if h5_writer:
                        h5_writer.append_data('ecu_l4000_event', [timekeeper.get_time_ns(), rd[0]])

                elif byte == L.LOGID_ECU_T1_HOFLO_TYPE_TS:
                    marker_ts = int.from_bytes(read(f, L.LOGID_ECU_T1_HOFLO_TYPE_DLEN), byteorder='little', signed=False)
                    # RETROSPECTIVE timestamp - event HAS occurred (b15 went 0→1)
                    # This is a time anchor event, marks ~65536 ticks from previous anchor
                    timekeeper.process_ts_event(marker_ts, is_hoflo=True)
                    print(f"{fmt_record(recordCnt, timekeeper)} HOFLO_TS: {marker_ts}")
                    # HOFLO not written to HDF5 - used only for time tracking

                elif byte == L.LOGID_ECU_F_INJ_ON_TYPE_PTS:
                    fi_on = int.from_bytes(read(f, L.LOGID_ECU_F_INJ_ON_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - this is when the event WILL happen, not when it occurred
                    # Do not advance time_ns based on this value
                    timekeeper.advance_time_by_ns(1)
                    print(f"{fmt_record(recordCnt, timekeeper)} FI_ON:  {fi_on}")
                    if h5_writer:
                        # TODO: implement prospective timestamp conversion
                        actual_time_ns = timekeeper.get_time_ns()
                        # Record as pending for combined bar dataset
                        h5_writer.append_injector_on('front', actual_time_ns, fi_on)

                elif byte == L.LOGID_ECU_F_INJ_DUR_TYPE_U16:
                    fi_dur = int.from_bytes(read(f, L.LOGID_ECU_F_INJ_DUR_DLEN), byteorder='little', signed=False)
                    print(f"{fmt_record(recordCnt, timekeeper)} FI_DUR: {fi_dur}")
                    if h5_writer:
                        # Pair with pending ON event to create combined bar
                        h5_writer.append_injector_duration('front', fi_dur)

                elif byte == L.LOGID_ECU_R_INJ_ON_TYPE_PTS:
                    ri_on = int.from_bytes(read(f, L.LOGID_ECU_R_INJ_ON_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - this is when the event WILL happen, not when it occurred
                    timekeeper.advance_time_by_ns(1)
                    print(f"{fmt_record(recordCnt, timekeeper)} RI_ON:  {ri_on}")
                    if h5_writer:
                        # TODO: implement prospective timestamp conversion
                        actual_time_ns = timekeeper.get_time_ns()
                        # Record as pending for combined bar dataset
                        h5_writer.append_injector_on('rear', actual_time_ns, ri_on)

                elif byte == L.LOGID_ECU_R_INJ_DUR_TYPE_U16:
                    ri_dur = int.from_bytes(read(f, L.LOGID_ECU_R_INJ_DUR_DLEN), byteorder='little', signed=False)
                    print(f"{fmt_record(recordCnt, timekeeper)} RI_DUR: {ri_dur}")
                    if h5_writer:
                        # Pair with pending ON event to create combined bar
                        h5_writer.append_injector_duration('rear', ri_dur)

                elif byte == L.LOGID_ECU_F_COIL_ON_TYPE_PTS:
                    fc_on = int.from_bytes(read(f, L.LOGID_ECU_F_COIL_ON_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} FC_ON:  {fc_on}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_front_coil_on_calc', [calc_time_ns, fc_on])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_front_coil_on_actual', [actual_time_ns, fc_on])
                            # Record as pending for combined bar dataset
                            h5_writer.append_coil_on('front_coil', actual_time_ns, fc_on)

                elif byte == L.LOGID_ECU_F_COIL_OFF_TYPE_PTS:
                    fc_off = int.from_bytes(read(f, L.LOGID_ECU_F_COIL_OFF_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} FC_OFF: {fc_off}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_front_coil_off_calc', [calc_time_ns, fc_off])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_front_coil_off_actual', [actual_time_ns, fc_off])
                            # Pair with pending ON event to create combined bar
                            h5_writer.append_coil_off('front_coil', actual_time_ns)

                elif byte == L.LOGID_ECU_R_COIL_ON_TYPE_PTS:
                    rc_on = int.from_bytes(read(f, L.LOGID_ECU_R_COIL_ON_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} RC_ON:  {rc_on}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_rear_coil_on_calc', [calc_time_ns, rc_on])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_rear_coil_on_actual', [actual_time_ns, rc_on])
                            # Record as pending for combined bar dataset
                            h5_writer.append_coil_on('rear_coil', actual_time_ns, rc_on)

                elif byte == L.LOGID_ECU_R_COIL_OFF_TYPE_PTS:
                    rc_off = int.from_bytes(read(f, L.LOGID_ECU_R_COIL_OFF_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} RC_OFF: {rc_off}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_rear_coil_off_calc', [calc_time_ns, rc_off])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_rear_coil_off_actual', [actual_time_ns, rc_off])
                            # Pair with pending ON event to create combined bar
                            h5_writer.append_coil_off('rear_coil', actual_time_ns)

                elif byte == L.LOGID_ECU_F_COIL_MAN_ON_TYPE_PTS:
                    fcm_on = int.from_bytes(read(f, L.LOGID_ECU_F_COIL_MAN_ON_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} FC_MON: {fcm_on}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_front_coil_manual_on_calc', [calc_time_ns, fcm_on])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_front_coil_manual_on_actual', [actual_time_ns, fcm_on])
                            # Record as pending for combined bar dataset
                            h5_writer.append_coil_on('front_coil_manual', actual_time_ns, fcm_on)

                elif byte == L.LOGID_ECU_F_COIL_MAN_OFF_TYPE_PTS:
                    fcm_off = int.from_bytes(read(f, L.LOGID_ECU_F_COIL_MAN_OFF_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} FC_MOF: {fcm_off}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_front_coil_manual_off_calc', [calc_time_ns, fcm_off])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_front_coil_manual_off_actual', [actual_time_ns, fcm_off])
                            # Pair with pending ON event to create combined bar
                            h5_writer.append_coil_off('front_coil_manual', actual_time_ns)

                elif byte == L.LOGID_ECU_R_COIL_MAN_ON_TYPE_PTS:
                    rcm_on = int.from_bytes(read(f, L.LOGID_ECU_R_COIL_MAN_ON_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} RC_MON: {rcm_on}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_rear_coil_manual_on_calc', [calc_time_ns, rcm_on])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_rear_coil_manual_on_actual', [actual_time_ns, rcm_on])
                            # Record as pending for combined bar dataset
                            h5_writer.append_coil_on('rear_coil_manual', actual_time_ns, rcm_on)

                elif byte == L.LOGID_ECU_R_COIL_MAN_OFF_TYPE_PTS:
                    rcm_off = int.from_bytes(read(f, L.LOGID_ECU_R_COIL_MAN_OFF_DLEN), byteorder='little', signed=False)
                    # PROSPECTIVE timestamp - scheduled future event
                    print(f"{fmt_record(recordCnt, timekeeper)} RC_MOF: {rcm_off}")
                    if h5_writer:
                        calc_time_ns = timekeeper.get_time_ns()
                        h5_writer.append_data('ecu_rear_coil_manual_off_calc', [calc_time_ns, rcm_off])
                        actual_time_ns = timekeeper.get_time_ns()  # TODO: implement prospective timestamp conversion
                        if actual_time_ns is not None:
                            h5_writer.append_data('ecu_rear_coil_manual_off_actual', [actual_time_ns, rcm_off])
                            # Pair with pending ON event to create combined bar
                            h5_writer.append_coil_off('rear_coil_manual', actual_time_ns)

                elif byte == L.LOGID_ECU_F_IGN_DLY_TYPE_0P8:
                    b = read(f, L.LOGID_ECU_F_IGN_DLY_DLEN)[0]
                    advance = ((b/256)*90.0) - 18
                    print(f"{fmt_record(recordCnt, timekeeper)} FIA:    {advance:.1f}")
                    if h5_writer:
                        h5_writer.append_data('ecu_front_ign_delay', [timekeeper.get_time_ns(), advance])

                elif byte == L.LOGID_ECU_R_IGN_DLY_TYPE_0P8:
                    b = read(f, L.LOGID_ECU_R_IGN_DLY_DLEN)[0]
                    advance = ((b/256)*90.0) - 18
                    print(f"{fmt_record(recordCnt, timekeeper)} RIA:    {advance:.1f}")
                    if h5_writer:
                        h5_writer.append_data('ecu_rear_ign_delay', [timekeeper.get_time_ns(), advance])

                elif byte == L.LOGID_ECU_5MILLISEC_EVENT_TYPE_V:
                    ignore = read(f, L.LOGID_ECU_5MILLISEC_EVENT_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} 5MS:")
                    if h5_writer:
                        h5_writer.append_data('ecu_marker_5ms', timekeeper.get_time_ns())

                elif byte == L.LOGID_ECU_CRANK_P6_MAX_TYPE_V:
                    ignore = read(f, L.LOGID_ECU_CRANK_P6_MAX_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} CMX:    Crank Max")
                    if h5_writer:
                        h5_writer.append_data('ecu_marker_p6_max', timekeeper.get_time_ns())

                elif byte == L.LOGID_ECU_FUEL_PUMP_TYPE_B:
                    pumpstate = read(f, L.LOGID_ECU_FUEL_PUMP_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} FP:     {pumpstate}")
                    if h5_writer:
                        h5_writer.append_data('ecu_fuel_pump', [timekeeper.get_time_ns(), pumpstate])

                elif byte == L.LOGID_ECU_ECU_ERROR_L000C_TYPE_U8:
                    L000C = read(f, L.LOGID_ECU_ECU_ERROR_L000C_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} ELC:    " + "{:08b} ".format(L000C), end="")
                    decodeL000C(L000C)
                    if h5_writer:
                        h5_writer.append_data('ecu_error_L000C', [timekeeper.get_time_ns(), L000C])

                elif byte == L.LOGID_ECU_ECU_ERROR_L000D_TYPE_U8:
                    L000D = read(f, L.LOGID_ECU_ECU_ERROR_L000D_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} ELD:    " + "{:08b} ".format(L000D), end="")
                    decodeL000D(L000D)
                    if h5_writer:
                        h5_writer.append_data('ecu_error_L000D', [timekeeper.get_time_ns(), L000D])

                elif byte == L.LOGID_ECU_ECU_ERROR_L000E_TYPE_U8:
                    L000E = read(f, L.LOGID_ECU_ECU_ERROR_L000E_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} ELE:    " + "{:08b} ".format(L000E), end="")
                    decodeL000C(L000E)
                    if h5_writer:
                        h5_writer.append_data('ecu_error_L000E', [timekeeper.get_time_ns(), L000E])

                elif byte == L.LOGID_ECU_ECU_ERROR_L000F_TYPE_U8:
                    L000F = read(f, L.LOGID_ECU_ECU_ERROR_L000F_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} ELF:    " + "{:08b} ".format(L000F), end="")
                    decodeL000D(L000F)
                    if h5_writer:
                        h5_writer.append_data('ecu_error_L000F', [timekeeper.get_time_ns(), L000F])

                elif byte == L.LOGID_ECU_RAW_VTA_TYPE_U16:
                    vta_raw = int.from_bytes(read(f, L.LOGID_ECU_RAW_VTA_DLEN), byteorder='little', signed=False)

                    # Extract VTA value (lower 10 bits) and timer bits (upper 6 bits)
                    vta = vta_raw & 0x3FF  # Lower 10 bits
                    timer_bits = (vta_raw >> 10) & 0x3F  # Upper 6 bits

                    # If upper 6 bits are non-zero, use them to update time
                    if timer_bits != 0:
                        # Timer bits provide upper 6 bits of the 16-bit timer
                        # Try to update time, but ignore if it would go backwards
                        current_time = timekeeper.get_time_ns()
                        if timekeeper.try_update_timer_bits(timer_bits):
                            # Time was successfully advanced
                            pass
                        else:
                            # Time would have gone backwards, ignore the update
                            timekeeper.set_time_ns(current_time)

                    timekeeper.advance_time_by_ns(1)
                    print(f"{fmt_record(recordCnt, timekeeper)} VTA:    {vta} ADC{f' (timer={timer_bits:02X})' if timer_bits != 0 else ''}")
                    if h5_writer:
                        h5_writer.append_data('ecu_throttle_adc', [timekeeper.get_time_ns(), vta])

                elif byte == L.LOGID_ECU_RAW_MAP_TYPE_U8:
                    map_adc = read(f, L.LOGID_ECU_RAW_MAP_DLEN)[0]
                    map_kpa = convertPressureSensorAdcToKpa(map_adc)
                    print(f"{fmt_record(recordCnt, timekeeper)} MAP:    {map_kpa:.1f} kPa")
                    if h5_writer:
                        h5_writer.append_data('ecu_map_kpa', [timekeeper.get_time_ns(), map_kpa])

                elif byte == L.LOGID_ECU_RAW_AAP_TYPE_U8:
                    aap_adc = read(f, L.LOGID_ECU_RAW_AAP_DLEN)[0]
                    aap_kpa = convertPressureSensorAdcToKpa(aap_adc)
                    print(f"{fmt_record(recordCnt, timekeeper)} AAP:    {aap_kpa:.1f} kPa")
                    if h5_writer:
                        h5_writer.append_data('ecu_aap_kpa', [timekeeper.get_time_ns(), aap_kpa])

                elif byte == L.LOGID_ECU_RAW_THW_TYPE_U8:
                    thw_adc = read(f, L.LOGID_ECU_RAW_THW_DLEN)[0]

                    thw_C = convertApriliaTempSensorAdcToDegC(thw_adc)
                    print(f"{fmt_record(recordCnt, timekeeper)} THW:    {thw_C:.1f} C")
                    if h5_writer:
                        h5_writer.append_data('ecu_coolant_temp_c', [timekeeper.get_time_ns(), thw_C])

                elif byte == L.LOGID_ECU_RAW_THA_TYPE_U8:
                    tha_adc = read(f, L.LOGID_ECU_RAW_THA_DLEN)[0]

                    tha_C = convertApriliaTempSensorAdcToDegC(tha_adc)
                    print(f"{fmt_record(recordCnt, timekeeper)} THA:    {tha_C:.1f} C")
                    if h5_writer:
                        h5_writer.append_data('ecu_air_temp_c', [timekeeper.get_time_ns(), tha_C])

                elif byte == L.LOGID_ECU_RAW_VM_TYPE_U8:
                    # The VM input divides the input voltage by 4 via resistor divider
                    # then feeds it to an ADC where 5V represents the max ADC value 0xFF.
                    adc = read(f, L.LOGID_ECU_RAW_VM_DLEN)[0]
                    vm_V = (adc/256) * 5 * 4
                    print(f"{fmt_record(recordCnt, timekeeper)} VM:     {vm_V:.2f} V")
                    if h5_writer:
                        h5_writer.append_data('ecu_battery_voltage_v', [timekeeper.get_time_ns(), vm_V])

                elif byte == L.LOGID_ECU_PORTG_DB_TYPE_U8:
                    portg = read(f, L.LOGID_ECU_PORTG_DB_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} PTG:    " + "{:08b}".format(portg))
                    if h5_writer:
                        h5_writer.append_data('ecu_portg_debug', [timekeeper.get_time_ns(), portg])

                elif byte == L.LOGID_ECU_CRANKREF_START_TYPE_TS:
                    cr_ts = int.from_bytes(read(f, L.LOGID_ECU_CRANKREF_START_DLEN), byteorder='little', signed=False)
                    # RETROSPECTIVE timestamp - event HAS occurred, advance time_ns
                    timekeeper.process_ts_event(cr_ts)
                    # Save timestamp AFTER advancing - this is when the current CR event occurred
                    # This marks the END of the previous period, which is what the RPM calculation represents
                    rpm_timestamp_ns = timekeeper.get_time_ns()
                    if h5_writer:
                        h5_writer.append_data('ecu_crankref_timestamp', [timekeeper.get_time_ns(), cr_ts])

                    if (cr_ts_prev > -1):
                        elapsed = cr_ts - cr_ts_prev
                        if (elapsed<0):
                            elapsed += 65536

                    cr_ts_prev = cr_ts

                    # Calculate spark advance if this is the right CRID (will be determined in CRID handler)
                    # Store for potential printing below
                    spark_advance_data = None

                    if (elapsed < 0):
                        print(f"{fmt_record(recordCnt, timekeeper)} CRK_TS: {cr_ts}")
                    else:
                        # Calculate instantaneous RPM from single interval (30 degrees)
                        # elapsed is in 2μs ticks for one 30° interval
                        # RPM = (60 sec/min * 1000000 μs/sec) / (elapsed * 2 μs/tick * 2 intervals/tooth * 6 teeth/rev)
                        rpm = 60000000 / (elapsed * 2 * 6)

                        # Store 64-bit nanosecond timestamp for smoothed RPM calculation
                        # Using ns timestamps instead of 16-bit ticks avoids overflow at low RPM
                        crank_ts_history.append(rpm_timestamp_ns)

                        # Calculate smoothed RPM over last 12 intervals (2 full rotations = 360°)
                        # Need 13 timestamps to have 12 intervals
                        if len(crank_ts_history) >= 13:
                            # Calculate elapsed time over 12 intervals (no wraparound issues with 64-bit ns)
                            oldest_ts_ns = crank_ts_history[0]
                            newest_ts_ns = crank_ts_history[12]  # 13th timestamp (index 12)
                            total_elapsed_ns = newest_ts_ns - oldest_ts_ns

                            # RPM from 12 intervals (360 degrees = 1 full rotation)
                            # total_elapsed_ns is in nanoseconds for 12 intervals (360°)
                            # RPM = (60 sec/min * 1000000000 ns/sec) / total_elapsed_ns
                            rpm_avg = 60000000000 / total_elapsed_ns
                        else:
                            # Not enough history yet, use instantaneous RPM
                            rpm_avg = rpm

                        print(f"{fmt_record(recordCnt, timekeeper)} CRK_TS: {cr_ts}, elapsed: {elapsed}, RPM-INST {rpm:.0f}, RPM-AVG {rpm_avg:.0f}")

                        if h5_writer:
                            # Use rpm_timestamp_ns which captures the END of the period being measured
                            h5_writer.append_data('ecu_rpm_instantaneous', [rpm_timestamp_ns, rpm])
                            h5_writer.append_data('ecu_rpm_smoothed', [rpm_timestamp_ns, rpm_avg])

                elif byte == L.LOGID_ECU_CRANKREF_ID_TYPE_U8:
                    crid = read(f, L.LOGID_ECU_CRANKREF_ID_DLEN)[0]

                    # Store CR timestamp for spark advance calculation
                    # The CRID event is associated with the CRANK_TS that just arrived (cr_ts)
                    # So CRID N began at time cr_ts
                    if cr_ts >= 0:
                        timekeeper.set_cr_timestamp(crid, cr_ts)

                    # Update current CRID state (must be AFTER set_cr_timestamp to track previous correctly)
                    timekeeper.set_crankref_id(crid)

                    # Calculate spark advance if this is CRID N+2 (CR6 or CR11)
                    # Print on CRID line with advance values
                    if crid == 6 or crid == 11:
                        spark_results = timekeeper.calculate_and_write_spark_advance(crid, h5_writer)
                        cyl_name = "Front" if crid == 6 else "Rear"
                        advance_strs = []
                        if spark_results['spark1_advance'] is not None:
                            advance_strs.append(f"S1:{spark_results['spark1_advance']:.1f}°")
                        if spark_results['spark2_advance'] is not None:
                            advance_strs.append(f"S2:{spark_results['spark2_advance']:.1f}°")
                        if advance_strs:
                            advance_info = f" ({cyl_name}: {', '.join(advance_strs)})"
                        else:
                            advance_info = ""
                        print(f"{fmt_record(recordCnt, timekeeper)} CRID:   {crid}{advance_info}")
                    else:
                        print(f"{fmt_record(recordCnt, timekeeper)} CRID:   {crid}")

                    if h5_writer:
                        h5_writer.append_data('ecu_crankref_id', [timekeeper.get_time_ns(), crid])

                    if (elapsed > 0):
                        fco = rco = 0
                        if crid == 5:
                            fco = fc_off
                        elif crid == 10:
                            rco = rc_off
                        if (fi_dur != 0):
                            fi_dur = 0
                        if (ri_dur != 0):
                            ri_dur = 0

                    # CRID sequence validation
                    if (cridPrev >= 0):
                        expectedId = cridPrev + 1
                        if (expectedId > 11):
                            expectedId = 0
                        if (crid != expectedId):
                            time_str = f"{timekeeper.get_time_ns() / 1e9:.6f}s"
                            sys.stderr.write(f"CRID ERROR at {time_str}: expected CRID={expectedId}, observed CRID={crid}\n")
                            print(f"{fmt_record(recordCnt, timekeeper)} ERROR: expected CRID {expectedId}, saw {crid}")
                    elif cridPrev == -1:
                        # First CRID after CAM (or start of log) should be 0
                        if crid != 0:
                            time_str = f"{timekeeper.get_time_ns() / 1e9:.6f}s"
                            sys.stderr.write(f"CRID ERROR at {time_str}: first CRID after CAM should be 0, observed CRID={crid}\n")
                            print(f"{fmt_record(recordCnt, timekeeper)} ERROR: first CRID after CAM should be 0, saw {crid}")

                    # Update previous CRID for next comparison
                    cridPrev = crid

                elif byte == L.LOGID_ECU_T1_HOFLO_TYPE_TS:
                    time_marker_ts = int.from_bytes(read(f, L.LOGID_ECU_T1_HOFLO_TYPE_DLEN), byteorder='little', signed=False)
                    # RETROSPECTIVE timestamp - tracks time when engine not rotating
                    timekeeper.process_ts_event(time_marker_ts, is_hoflo=True)
                    print(f"{fmt_record(recordCnt, timekeeper)} TIME_MKR: {time_marker_ts}")
                    # HOFLO not written to HDF5 - used only for time tracking

                elif byte == L.LOGID_ECU_CAMSHAFT_TYPE_TS:
                    cam_ts = int.from_bytes(read(f, L.LOGID_ECU_CAMSHAFT_DLEN), byteorder='little', signed=False)
                    # RETROSPECTIVE timestamp - event HAS occurred, advance time_ns
                    timekeeper.process_ts_event(cam_ts)
                    print(f"{fmt_record(recordCnt, timekeeper)} CAM_TS: {cam_ts}")
                    if h5_writer:
                        h5_writer.append_data('ecu_camshaft_timestamp', [timekeeper.get_time_ns(), cam_ts])

                    # CAM event should reset CRID sequence - next CRID should be 0
                    # Check if previous CRID was 11 (expected before CAM)
                    if cridPrev >= 0 and cridPrev != 11:
                        time_str = f"{timekeeper.get_time_ns() / 1e9:.6f}s"
                        sys.stderr.write(f"CRID ERROR at {time_str}: CAM event but previous CRID={cridPrev} (expected 11)\n")
                    # Reset CRID tracking - next CRID should be 0
                    cridPrev = -1

                elif byte == L.LOGID_ECU_CAM_ERR_TYPE_U8:
                    camErr = read(f, L.LOGID_ECU_CAM_ERR_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} CAM ERR: {camErr:02X}")
                    if h5_writer:
                        h5_writer.append_data('ecu_cam_error', [timekeeper.get_time_ns(), camErr])

                elif byte == L.LOGID_ECU_SPRK_X1_TYPE_PTS:
                    spx1_ts_raw = int.from_bytes(read(f, L.LOGID_ECU_SPRK_X1_DLEN), byteorder='little', signed=False)

                    # Apply spark delay correction
                    # There is a delay between when the spark is scheduled and when it is observed
                    spx1_ts_corrected = spx1_ts_raw - TimeKeeper.SPARK_DELAY_X1_TICKS
                    if spx1_ts_corrected < 0:
                        spx1_ts_corrected += TimeKeeper.TIMER_MAX

                    # RETROSPECTIVE timestamp - spark HAS fired
                    # Convert raw timestamp to actual time when spark occurred
                    actual_spark_time_ns = timekeeper.process_retrospective_t_event(spx1_ts_raw)
                    actual_spark_time_secs = actual_spark_time_ns / 1000000000.0

                    # Check if this spark is in a valid CRID range
                    # Both SPRK1 and SPRK2 fire in same window (dual-plug per cylinder)
                    is_valid_crid, is_front_cylinder = timekeeper.is_spark_in_valid_crid()

                    # Check if this is the first SPRK1 after CRID change (filter out bounces)
                    is_first_spark = not timekeeper.spark_x1_seen_this_crid
                    timekeeper.spark_x1_seen_this_crid = True

                    # Print to human-readable output (advance will be calculated later when CRID arrives)
                    cyl_name = "Front" if is_front_cylinder else "Rear" if is_front_cylinder is not None else "Unknown"
                    if not is_valid_crid:
                        print(f"{fmt_record(recordCnt, timekeeper)} SPRK1_TS: {spx1_ts_raw} - {TimeKeeper.SPARK_DELAY_X1_TICKS} = {spx1_ts_corrected} (actual: {actual_spark_time_secs}) [IGNORED - wrong CRID]")
                    elif is_first_spark:
                        print(f"{fmt_record(recordCnt, timekeeper)} SPRK1_TS: {spx1_ts_raw} - {TimeKeeper.SPARK_DELAY_X1_TICKS} = {spx1_ts_corrected} (actual: {actual_spark_time_secs}, {cyl_name} cyl) [advance pending]")
                    else:
                        print(f"{fmt_record(recordCnt, timekeeper)} SPRK1_TS: {spx1_ts_raw} - {TimeKeeper.SPARK_DELAY_X1_TICKS} = {spx1_ts_corrected} (actual: {actual_spark_time_secs}) [IGNORED - bounce]")

                    # Store spark for advance calculation and write to HDF5
                    if is_first_spark and is_valid_crid:
                        # Store corrected spark timestamp - advance will be calculated when CRID N+2 arrives
                        timekeeper.store_pending_spark(spx1_ts_corrected, actual_spark_time_ns, is_sprk1=True)
                        # Write to HDF5 if enabled
                        if h5_writer:
                            h5_writer.append_data('ecu_spark_x1', [actual_spark_time_ns, spx1_ts_raw])

                elif byte == L.LOGID_ECU_SPRK_X2_TYPE_PTS:
                    spx2_ts_raw = int.from_bytes(read(f, L.LOGID_ECU_SPRK_X2_DLEN), byteorder='little', signed=False)

                    # Apply spark delay correction
                    # There is a delay between when the spark is scheduled and when it is observed
                    spx2_ts_corrected = spx2_ts_raw - TimeKeeper.SPARK_DELAY_X2_TICKS
                    if spx2_ts_corrected < 0:
                        spx2_ts_corrected += TimeKeeper.TIMER_MAX

                    # RETROSPECTIVE timestamp - spark HAS fired
                    # Convert raw timestamp to actual time when spark occurred
                    actual_spark_time_ns = timekeeper.process_retrospective_t_event(spx2_ts_raw)
                    actual_spark_time_secs = actual_spark_time_ns / 1000000000.0

                    # Check if this spark is in a valid CRID range
                    # Both SPRK1 and SPRK2 fire in same window (dual-plug per cylinder)
                    is_valid_crid, is_front_cylinder = timekeeper.is_spark_in_valid_crid()

                    # Check if this is the first SPRK2 after CRID change (filter out bounces)
                    is_first_spark = not timekeeper.spark_x2_seen_this_crid
                    timekeeper.spark_x2_seen_this_crid = True

                    # Print to human-readable output (advance will be calculated later when CRID arrives)
                    cyl_name = "Front" if is_front_cylinder else "Rear" if is_front_cylinder is not None else "Unknown"
                    if not is_valid_crid:
                        print(f"{fmt_record(recordCnt, timekeeper)} SPRK2_TS: {spx2_ts_raw} - {TimeKeeper.SPARK_DELAY_X2_TICKS} = {spx2_ts_corrected} (actual: {actual_spark_time_secs}) [IGNORED - wrong CRID]")
                    elif is_first_spark:
                        print(f"{fmt_record(recordCnt, timekeeper)} SPRK2_TS: {spx2_ts_raw} - {TimeKeeper.SPARK_DELAY_X2_TICKS} = {spx2_ts_corrected} (actual: {actual_spark_time_secs}, {cyl_name} cyl) [advance pending]")
                    else:
                        print(f"{fmt_record(recordCnt, timekeeper)} SPRK2_TS: {spx2_ts_raw} - {TimeKeeper.SPARK_DELAY_X2_TICKS} = {spx2_ts_corrected} (actual: {actual_spark_time_secs}) [IGNORED - bounce]")

                    # Store spark for advance calculation and write to HDF5
                    if is_first_spark and is_valid_crid:
                        # Store corrected spark timestamp - advance will be calculated when CRID N+2 arrives
                        timekeeper.store_pending_spark(spx2_ts_corrected, actual_spark_time_ns, is_sprk1=False)
                        # Write to HDF5 if enabled
                        if h5_writer:
                            h5_writer.append_data('ecu_spark_x2', [actual_spark_time_ns, spx2_ts_raw])

                elif byte == L.LOGID_ECU_NOSPARK_TYPE_U8:
                    sparkErr = read(f, L.LOGID_ECU_NOSPARK_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} NOSPRK: {sparkErr:02X}")
                    if h5_writer:
                        h5_writer.append_data('ecu_nospark', [timekeeper.get_time_ns(), sparkErr])

                # EP-specific events
                elif byte == L.LOGID_GEN_EP_LOG_VER_TYPE_U8:
                    rd = read(f, L.LOGID_GEN_EP_LOG_VER_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} EPV:    {rd[0]}")

                elif byte == L.LOGID_EP_FIND_NAME_TYPE_U8:
                    # Each write to this address appends the next byte as a char to the EPROM_ID_STR
                    c = read(f, L.LOGID_EP_FIND_NAME_DLEN)[0]
                    if (c != 0):
                        # Print intermediate bytes (log ID + data byte)
                        if showBinData:
                            print(f"0x{address-2:08X}: {byte:02X} {c:02X} ")
                        epromIdString = "".join([epromIdString, chr(c)])
                        #if h5_writer:
                        #    h5_writer.current_eprom_name += chr(c)
                    else:
                        currentEpromId = epromIdString
                        epromIdString = ""
                        print(f"{fmt_record(recordCnt, timekeeper)} FIND:   {currentEpromId}")

                elif byte == L.LOGID_EP_LOAD_NAME_TYPE_U8:
                    # Each write to this address appends the next byte as a char to the EPROM_ID_STR
                    c = read(f, L.LOGID_EP_LOAD_NAME_DLEN)[0]
                    if (c != 0):
                        # Print intermediate bytes (log ID + data byte)
                        if showBinData:
                            print(f"0x{address-2:08X}: {byte:02X} {c:02X} ")
                        epromIdString = "".join([epromIdString, chr(c)])
                        if h5_writer:
                            h5_writer.current_eprom_name += chr(c)
                    else:
                        currentEpromId = epromIdString
                        epromIdString = ""
                        print(f"{fmt_record(recordCnt, timekeeper)} LOAD:   {currentEpromId}")

                elif byte == L.LOGID_EP_LOAD_ADDR_TYPE_U16:
                    epromStartAddr = int.from_bytes(read(f, L.LOGID_EP_LOAD_ADDR_DLEN), byteorder='little', signed=False)
                    print(f"{fmt_record(recordCnt, timekeeper)} ADDR:   0x{epromStartAddr:04X}")
                    if h5_writer:
                        h5_writer.current_eprom_addr = epromStartAddr

                elif byte == L.LOGID_EP_LOAD_LEN_TYPE_U16:
                    epromLen = int.from_bytes(read(f, L.LOGID_EP_LOAD_LEN_DLEN), byteorder='little', signed=False)
                    print(f"{fmt_record(recordCnt, timekeeper)} LEN:    0x{epromLen:04X}")
                    if h5_writer:
                        h5_writer.current_eprom_len = epromLen

                elif byte == L.LOGID_EP_LOAD_ERR_TYPE_U8:
                    loadErr = read(f, L.LOGID_EP_LOAD_ERR_DLEN)[0]
                    if loadErr == L.LOGID_EP_LOAD_ERR_VAL_NOERR:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_NOERR")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_NOTFOUND:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_NOTFOUND")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_NONAME:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_NONAME")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_CKSUMERR:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_CKSUMERR")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_VERIFYERR:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_VERIFYERR")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_BADOFFSET:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_BADOFFSET")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_BADLENGTH:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_BADLENGTH")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_NODAUGHTERBOARDKEY:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_NODAUGHTERBOARDKEY")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_NOMEMKEY:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_NOMEMKEY")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_M3FAIL:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_M3FAIL")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_MISSINGKEYSTART:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_MISSING_KEY_START")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_MISSINGKEYLENGTH:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_MISSING_KEY_LENGTH")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_MISSINGKEYM3:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_KEY_M3")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_BADM3BSONTYPE:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_BAD_M3_BSON_TYPE")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_BADM3VALUE:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_BAD_M3_VALUE")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_NOBINKEY:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_NOBINKEY")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_BADBINLENGTH:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_BADBINLENGTH")
                    elif loadErr == L.LOGID_EP_LOAD_ERR_VAL_BADBINSUBTYPE:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   ERR_BADBINSUBTYPE")
                    else:
                        print(f"{fmt_record(recordCnt, timekeeper)} STAT:   *** Unknown error: 0x{loadErr:02X}")

                    # Finalize EPROM load record for HDF5
                    if h5_writer:
                        # Add complete EPROM load record to metadata list
                        if h5_writer.current_eprom_name and h5_writer.current_eprom_addr is not None and h5_writer.current_eprom_len is not None:
                            h5_writer.eprom_loads.append((
                                h5_writer.current_eprom_name.encode('utf-8'),
                                h5_writer.current_eprom_addr,
                                h5_writer.current_eprom_len,
                                loadErr
                            ))
                            # Reset for next load
                            h5_writer.current_eprom_name = ""
                            h5_writer.current_eprom_addr = None
                            h5_writer.current_eprom_len = None

                # WP-specific events
                elif byte == L.LOGID_GEN_WP_LOG_VER_TYPE_U8:
                    rd = read(f, L.LOGID_GEN_WP_LOG_VER_DLEN)
                    print(f"{fmt_record(recordCnt, timekeeper)} WPV:    {rd[0]}")

                elif byte == L.LOGID_WP_CSECS_TYPE_U8:
                    csecs = read(f, L.LOGID_WP_CSECS_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} CS:     {csecs:02}")
                    if h5_writer:
                        h5_writer.temp_gps_csecs = csecs

                elif byte == L.LOGID_WP_SECS_TYPE_U8:
                    global gps_last_sec_time_ns, gps_first_sec_time_ns, gps_sec_count
                    secs = read(f, L.LOGID_WP_SECS_DLEN)[0]

                    # Update global time tracking
                    timekeeper.advance_time_by_ns(1)

                    # Track GPS SEC events for drift calculation
                    if gps_last_sec_time_ns < 0:
                        # First GPS SEC - just record it
                        print(f"{fmt_record(recordCnt, timekeeper)} SEC:    {secs:02}  (first GPS SEC)")
                    elif gps_first_sec_time_ns < 0:
                        # Second GPS SEC - use this as the reference point for drift calculation
                        gps_first_sec_time_ns = global_time_ns
                        elapsed_since_last_ns = global_time_ns - gps_last_sec_time_ns
                        print(f"{fmt_record(recordCnt, timekeeper)} SEC:    {secs:02}  " +
                              f"(Δlast: {elapsed_since_last_ns/1e9:.6f}s, reference point for drift tracking)")
                    else:
                        # Third and subsequent GPS SEC events - calculate drift
                        gps_sec_count += 1

                        # Calculate elapsed time since last SEC
                        elapsed_since_last_ns = global_time_ns - gps_last_sec_time_ns

                        # Calculate total elapsed retrospective time since second GPS SEC
                        total_elapsed_ns = global_time_ns - gps_first_sec_time_ns
                        total_elapsed_sec = total_elapsed_ns / 1e9

                        # Calculate expected elapsed time based on GPS SEC count
                        # (each SEC event should be ~1 second apart)
                        expected_elapsed_sec = float(gps_sec_count)

                        # Calculate drift: positive means clock is running fast, negative means slow
                        drift_sec = total_elapsed_sec - expected_elapsed_sec
                        drift_ppm = (drift_sec / expected_elapsed_sec) * 1e6 if expected_elapsed_sec > 0 else 0

                        print(f"{fmt_record(recordCnt, timekeeper)} SEC:    {secs:02}  " +
                              f"(Δlast: {elapsed_since_last_ns/1e9:.6f}s, " +
                              f"Σretro: {total_elapsed_sec:.3f}s, " +
                              f"drift: {drift_sec:+.3f}s = {drift_ppm:+.1f}ppm)")

                    gps_last_sec_time_ns = global_time_ns

                    if h5_writer:
                        h5_writer.temp_gps_secs = secs

                elif byte == L.LOGID_WP_MINS_TYPE_U8:
                    mins = read(f, L.LOGID_WP_MINS_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} MIN:    {mins:02}")
                    if h5_writer:
                        h5_writer.temp_gps_mins = mins

                elif byte == L.LOGID_WP_HOURS_TYPE_U8:
                    hours = read(f, L.LOGID_WP_HOURS_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} HRS:    {hours:02}")
                    if h5_writer:
                        h5_writer.temp_gps_hours = hours

                elif byte == L.LOGID_WP_DATE_TYPE_U8:
                    date = read(f, L.LOGID_WP_DATE_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} DT:     {date:02}")
                    if h5_writer:
                        h5_writer.temp_gps_date = date

                elif byte == L.LOGID_WP_MONTH_TYPE_U8:
                    month = read(f, L.LOGID_WP_MONTH_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} MON:    {month:02}")
                    if h5_writer:
                        h5_writer.temp_gps_month = month

                elif byte == L.LOGID_WP_YEAR_TYPE_U8:
                    year = read(f, L.LOGID_WP_YEAR_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} YR:     {year:02}")
                    if h5_writer:
                        h5_writer.temp_gps_year = year
                        # Year is the last GPS time field - record this for back-calculation if first time
                        if h5_writer.gps_first_time is None and hasattr(h5_writer, 'temp_gps_csecs'):
                            h5_writer.gps_first_time = (
                                h5_writer.temp_gps_csecs,
                                h5_writer.temp_gps_secs,
                                h5_writer.temp_gps_mins,
                                h5_writer.temp_gps_hours,
                                h5_writer.temp_gps_date,
                                h5_writer.temp_gps_month,
                                h5_writer.temp_gps_year
                            )
                            h5_writer.gps_sync_time_ns = timekeeper.get_time_ns()

                elif byte == L.LOGID_WP_FIXTYPE_TYPE_U8:
                    fix = read(f, L.LOGID_WP_FIXTYPE_DLEN)[0]
                    print(f"{fmt_record(recordCnt, timekeeper)} FIX:    {fix}")
                    if h5_writer:
                        h5_writer.append_data('gps_fix_type', [timekeeper.get_time_ns(), fix])

                elif byte == L.LOGID_WP_GPS_POSN_TYPE_8B:
                    # Position & Velocity data: 2 args in the 8 bytes that follow.
                    # You have to use integer division here or else read() fails silently!
                    alen = L.LOGID_WP_GPS_POSN_DLEN // 2
                    lat =  int.from_bytes(read(f, alen, newLine=False), byteorder='little', signed=True) / 10000000.0
                    long = int.from_bytes(read(f, alen), byteorder='little', signed=True) / 10000000.0
                    print(f"{fmt_record(recordCnt, timekeeper)} GPS_POSN: {lat:.8f} {long:.8f}")
                    if h5_writer:
                        h5_writer.append_data('gps_position', [timekeeper.get_time_ns(), lat, long])

                elif byte == L.LOGID_WP_GPS_VELO_TYPE_U16:
                    # Velocity is encoded in a uint16_t as (velocity*10) MPH
                    vel =  int.from_bytes(read(f, L.LOGID_WP_GPS_VELO_DLEN), byteorder='little', signed=True) / 10.0
                    if (vel >= 2000):
                        # Trouble: This reading is way too fast!
                        print(f"ERR: At byte {(f.tell()-L.LOGID_WP_GPS_VELO_DLEN):08X}: L.LOGID_WP_GPS_VELO_TYPE_U16 is beyond 200 MPH: {vel/10.0}, ignoring!", file=sys.stderr)
                    else:
                        print(f"{fmt_record(recordCnt, timekeeper)} GPS_VEL: {vel:.1f}")
                        if h5_writer:
                            h5_writer.append_data('gps_velocity_mph', [timekeeper.get_time_ns(), vel])

                elif byte == L.LOGID_WP_GPS_PPS_TYPE_V:
                    # A GPS PPS event has no data, just the fact that it occurred marks the start of a new UTC second
                    # Print newline after the event ID byte that was already printed
                    if showBinData:
                        print("")
                    stats = timekeeper.process_pps_event()
                    if stats:
                        print(f"{fmt_record(recordCnt, timekeeper)} {stats}")
                    else:
                        print(f"{fmt_record(recordCnt, timekeeper)} GPS_PPS (first, baseline established)")
                    if h5_writer:
                        h5_writer.append_data('gps_pps', [timekeeper.get_time_ns()])

                elif byte == L.LOGID_WP_WR_TIME_TYPE_U16:
                    # Time follows as 2 bytes, LSB first
                    wrTime = int.from_bytes(read(f, 2), byteorder='little', signed=False)
                    print(f"{fmt_record(recordCnt, timekeeper)} WRT:    {wrTime} msec")
                    if h5_writer:
                        h5_writer.append_data('wp_fs_write_time_ms', [timekeeper.get_time_ns(), wrTime])

                elif byte == L.LOGID_WP_SYNC_TIME_TYPE_U16:
                    # Log filesystem sync() time follows as 2 bytes, LSB first
                    syncTime = int.from_bytes(read(f, 2), byteorder='little', signed=False)
                    print(f"{fmt_record(recordCnt, timekeeper)} SYT:    {syncTime} msec")
                    if h5_writer:
                        h5_writer.append_data('wp_fs_sync_time_ms', [timekeeper.get_time_ns(), syncTime])

                else:
                    print(f"{fmt_record(recordCnt, timekeeper)} ERR:    Unknown LOGID 0x{byte:02X}")
                    #read(f, 1)

            # End of file reached - print summary
            final_time_sec = timekeeper.get_time_ns() / 1e9
            file_size = f.tell()
            print(f"\n# Decoding complete: {recordCnt} records processed, {file_size} bytes read, {final_time_sec:.2f} seconds of data", file=sys.stderr)

    except FileNotFoundError:
        print(f"Error: File '{args.logfile}' not found.")
        return 1
    except Exception as e:
        print(f"Error processing file: {e}", file=sys.stderr)
        return 1
    finally:
        # Restore stdout if we redirected it
        if output_file:
            sys.stdout = old_stdout
            output_file.close()

        # Close HDF5 file if it was opened
        if h5_writer:
            h5_writer.close()
            if args.format == 'hdf5':
                print(f"# HDF5 file written successfully: {args.output}", file=sys.stderr)

        # print(f"Max difference between Beta and S-H calculations: {maxDiff:.1f}C")

if __name__ == "__main__":
    sys.exit(main())
